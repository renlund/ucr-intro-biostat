<<PRES_OR_HANDOUTS, cache=FALSE, echo=FALSE, include=TRUE, results='asis'>>=
if(!exists("HANDOUT")) HANDOUT <- FALSE
if(HANDOUT){
   cat("
\\documentclass[handout]{beamer}
\\usepackage{pgf,pgfpages}
\\pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=0.5in]
")
} else {
   cat("\\documentclass{beamer}")
}
rm(HANDOUT)
@

\usepackage{beamerthemeclassic}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{multicol}

\newcommand{\plot}{0.42}
\newcommand{\pr}{\mathbf{Prob}}
\newcommand{\el}{\mbox{\;or\;}}
\newcommand{\rymd}{\vspace{0.3cm}}

%\setbeamersize{text margin left=6mm, text margin right=2mm}  % DEFAULT
\setbeamersize{text margin left=3mm, text margin right=2mm}

\title{Introduction to Biostatistics \\ Lecture 10A}
\author{Henrik Renlund}
\date{April 14, 2016}

<<colors, cache=FALSE, echo=FALSE, include=FALSE>>=
.yellow <- wes_palette("Cavalcanti", 5)[1]
.green <- wes_palette("Cavalcanti", 5)[2]
.grey <- wes_palette("Cavalcanti", 5)[3]
.blue <- wes_palette("Cavalcanti", 5)[4]
.red <- wes_palette("Cavalcanti", 5)[5]
.seq3 <- brewer.pal(5, "YlGn")[2:4]
@


\begin{document} % >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

\frame{ % -------------------------------------------------------------------->
\begin{center}
\includegraphics[scale=0.65]{pics/stats_spiderman.jpg}
%\includegraphics[scale=0.30]{pics/StatPower.png}
\end{center}
\begin{flushright}
 {\tiny
  "Statistical Spidey knows the score." by Matthew B. Wall\\
  \url{https://computingforpsychologists.wordpress.com/2013/04/11/comment-on-the-button-et-al-2013-neuroscience-power-failure-article-in-nrn/}\\
 }
\end{flushright}
}
\frame{ % -------------------------------------------------------------------->
\titlepage
\begin{center}
\includegraphics[scale=0.2]{pics/ucrlogo.pdf}
\end{center}
}
% \frame{ % -------------------------------------------------------------------->
% \frametitle{Contents of Lecture 1-2}
% \tableofcontents
% }
\frame{ % -------------------------------------------------------------------->
\frametitle{What shall we learn today?}
This:
\rymd
\begin{itemize}
    \item statistical power
\end{itemize}
\rymd
and its relation to
\rymd
\begin{itemize}
    \item sample size calculations.
 \end{itemize}
 \rymd
(Bootstrap example in notes outside the scope of this course.)
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Power]{Power} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<power, cache=FALSE>>=
vizP <- function(eff = 1,
                 n = 10,
                 s = 1,
                 N = 15,
                 alfa = 0.05,
                 M = 5000,
                 out = TRUE
){
   set.seed(19790425)
   pow <- rep(NA,M); for(k in 1:M) pow[k] <- if(t.test(rnorm(n,eff,s))$p.value<0.05) 1 else 0
   POW <- mean(pow); POW
   M <- matrix(rnorm(n*N,mean=eff,sd=s), nrow=N, ncol=n)
   rownames(M) <- sprintf("sample %d", 1:N)
   colnames(M) <- sprintf("observation %d", 1:n)
   a <- min(M)
   b <- max(M)
   ci_ <- 0.5
   tsc <- 1.3
   if(out) x11(height=7, width=11)
   par(mar=c(1,1,1,1))
   plot(1,1,type='n',xlab="", ylab="",main="",yaxt='n',xaxt='n',bty='n',
        xlim=c(min(0,a),max(b,eff+2.5*s)), ylim=c(0.5,(N+5)))
   abline(h=N+ci_, lwd=2) # x-axis
   abline(v=0, lwd=2) # y-axis
   axis(side=1,at=c(0,eff),pos=N+ci_, hadj=-1, padj=-3.2, cex=tsc) # x-axis ticks
   abline(v=eff, lty=2, lwd=1, col="lightgray")
   ref <- dnorm(eff,eff,s)
   curve( 3*dnorm(x,eff,s)/ref+N+ci_, from=-10,to=10, add=TRUE, col="blue")
   text(x=eff+0.5*s, y=N+2*ci_+3*dnorm(eff+0.5*s,eff,s)/ref, paste("Pop. sd =", round(s,1)), cex=tsc, pos=4)
   text(x=eff+1.0*s, y=N+2*ci_+3*dnorm(eff+1.0*s,eff,s)/ref, paste("Sample size =", n), cex=tsc, pos=4)
   text(x=eff+1.5*s, y=N+2*ci_+3*dnorm(eff+1.5*s,eff,s)/ref, paste("Power =", round(POW,2)), cex=tsc, pos=4)
   arrows( x0=0, x1=eff, y0=N+5, y1=N+5, code=3,length = 0.15, angle = 25 )
   text(x=0+eff/2, y=N+4, pos=3, "Effect", cex=tsc)
   k <- 1
   for(k in 1:N){
      tmp <- M[k,]
      points(x=tmp,y=rep(k,n), pch=k, col="blue")
      ci <- t.test(tmp, conf.level=(1-alfa))$conf.int
      COL <- if( min(ci)<= 0 ) "red" else "green"
      arrows(x0=ci[1], x1=ci[2], y0=k-ci_,y1=k-ci_, code=3,length = 0.15, angle = 25,col=COL)
      points(x=mean(tmp), y=k-ci_, pch=k, col=COL, cex=1.2)
      rm(tmp, COL)
   }
}
@
\frame{ % -------------------------------------------------------------------->
\frametitle{How to make 'null' results meaningful}

Generally, it '$H_0$ not rejected' is uninformative
\emph{unless} we know that the study had a good chance
of detecting an effect that is interesting.

\rymd E.g:  "Two methods of pain relief were compared. The difference was not statistically significant."

\rymd This would be enhanced by;

\rymd "The study was designed to have a 90\% chance of
detecting a clinically significant difference
of 9 (on the VAS scale)".
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Attempt to visualize the power of a test}
Suppose we measure the effect of a drug
that on average does decrease the blood pressure
by a clinically significant amount (defined as 1 unit).

\rymd We measure the blood pressure on $n$ indivuals
before and after taking the drug.

\rymd Our data consist of $n$ 'indivual effects'
(before - after) which are positive if
the drug works. We assume these are Normal
with a standard deviation of 1 unit.

\rymd $H_0:$"average effect $= 0$" is determined
by creating a 95\% confidence interval for
the mean effect.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{15 samples of size 5}
<<n5>>=
vizP(n=5, out=FALSE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{15 samples of size 10}
<<n10>>=
vizP(n=10, out=FALSE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{15 samples of size 15}
<<n25>>=
vizP(n=15, out=FALSE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Power}
The power of a test is the probability
of rejecting the null hypothesis.

\rymd The power depends on
\begin{itemize}
\item effect size
\item sample size (maybe under your control)
\item the spread of the data
\item (the statistical test, significance level, etc.)
\end{itemize}

%\rymd (If there is no effect, the power = the error rate (the probability of rejecting a true null hypothesis.)

\rymd We want a test to have high power as soon as the effect is \emph{interesting}.

\rymd The power is often thought of as a function of sample size ($n$) and effect. Set
\begin{itemize}
   \item the power wanted,
   \item the effect to be \emph{at least interesting},
\end{itemize}
and figure out what $n$ needs to be.
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Example]{Example} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<foonctions, cache=FALSE, echo=FALSE, include=FALSE>>=
# load("data/F4_breastfeeding.Rdata")
p_boot <- function(things, m, bi=100){
   # m = sample size, bi = bootstrap iterations
   P <- rep(NA_real_, bi)
   for(indx in 1:bi){
      boot_sample <- sample(x = things, size = m, replace = TRUE)
      P[indx] <- wilcox.test(boot_sample, exact = FALSE)$p.value
   }
   P
}
# p_boot(things=y-x, m=14, bi=10)
pow_boot <- function(things, m, bi=100, mi=100, thresh=0.05, probs=c(0.05,0.5,.95)){
    # m = sample size, bi = bootstrap iterations, mi = meta iterations
   p_ge_thresh <- rep(NA_real_, mi)
   foljd <- floor(seq(1, mi, length.out=10))
   for(indx in 1:mi){
      p_tmp <- p_boot(things, m, bi)
      p_ge_thresh[indx] <- sum(p_tmp<thresh)/bi
      if(length(tmp <- which(foljd == indx))>0) cat(10*tmp, "% ready for m=", m, "\n")
   }
   M <- quantile(p_ge_thresh, probs = probs)
   names(M) <- paste0(100*probs, "%")
   M
}
# pow_boot(things=y-x, m=14)
search <- function(things, m, bi=100, mi=100, thresh=0.05, probs=c(0.05,0.5,.95)){
   m_n <- length(m)
   M <- matrix(NA_real_, nrow=m_n, ncol=4)
   colnames(M) <- c("size", paste0(100*probs, "%"))
   #rownames(M) <- m
   for(indx in 1:m_n){
      cat(" -- progress: ", indx, " of ", m_n, ". (m=",m[indx],") -- \n", sep="")
      M[indx,2:4] <- pow_boot(things, m[indx], bi, mi, thresh, probs)
   }
   M[,1] <- m
   as.data.frame(M)
}
# search(things=y-x, m=c(10,15))
@
\frame{ % -------------------------------------------------------------------->
\frametitle{Sample size calculation}
Recall the breastfeeding example from lecture 4.
{\tiny
<<bootstrap1, echo=FALSE, include=TRUE, results='asis', cache=FALSE>>=
load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
bord <- rbind(y,x,y-x, rank(abs(y-x)))
colnames(bord) <- 1:13
rownames(bord) <- c("bottle", "breast", "diff", "rank")
latex(bord,file="", title="pair")
@
}
<<bootstrap2, echo=FALSE, include=TRUE, results='asis'>>=
neg <- bord[4,bord[3,]<0]
pos <- bord[4,bord[3,]>0]
df <- data.frame(
    part = c("negative", "positive"),
    rank = c(paste0(neg, collapse=", "), paste0(pos, collapse=", ")),
    sum = c(sum(neg), sum(pos))
)
latex(df,file="",rowname=NULL)
WT <- wilcox.test(y-x,conf.int = T, exact=F)
# signif(WT$p.value,1)
# wilcox.test(y,x, paired = TRUE, exact=F)$p.value
# WT$estimate
@
The null hypothesis of no difference was tested with the Wilcoxon signed rank test. (This  tests for a shift in median.)

The $p$-value was \Sexpr{signif(wilcox.test(y-x, exact=F)$p.value,1)}
}
\frame{ % -------------------------------------------------------------------->
Think of this as being a pilot study and assume the data is representative of some target population. If the observed effect, a median shift of \Sexpr{round(WT$estimate)} days, is considered interesting (and thought to be true) what sample size would we need in order to show this?

\noindent \textbf{Two possible approaches:}
\begin{itemize}
    \item Make a  model (Normal? via transformation?) for the data and solve
    analytically or with software
    \item "Pull yourself up by your own bootstraps" - resample from the pilot study data.
\end{itemize}
In either case we will use the given sample:
<<bootstrap3, echo=FALSE, include=TRUE, results='asis'>>=
load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
cat("\\[z = \\{", paste((y-x), collapse=", "), "\\}\\]")
@
}
\begin{frame}[fragile] % ---------------------------------------------------->
\frametitle{Approximation with the R software}
Simple sample-size software exists on-line and possibly in your statistical
software. In (base) R we can use function for $t$-test to get a ballpark figure.
<<"power-calc",  echo = TRUE, results = 'hide'>>=
power.t.test(power = 0.8, delta = mean(z), sd = sd(z),
             type = "one.sample")
@
\begin{verbatim}
     One-sample t test power calculation

              n = 35.94785
          delta = 29.07692
             sd = 60.49995
      sig.level = 0.05
          power = 0.8
    alternative = two.sided
\end{verbatim}

Since the distribution is so skewed it is not unreasonable to think that the
Wilcoxon-test will be more powerful.
\end{frame}
\frame{ % -------------------------------------------------------------------->
\frametitle{Bootstrap method}
Resampling using the same same sample size (13).
<<bootstrap4, echo=FALSE, include=TRUE, results='asis', cache=FALSE>>=
load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
set.seed(20010713)
re1 <- sample(y-x, 14, T)
wt1 <- wilcox.test(re1, exact=F)
cat("\\[", paste(re1, collapse=", "), "\\]")
@
We are interested in the power of the test, so we want to see how often the null is rejected. For that purpose we collect the $p$-value. In  this case it is \Sexpr{signif(wt1$p.value, 2)}.

Now lets repeat this process 100 times. What kind of $p$-values do we get?
<<bootstrap5, echo=FALSE, include=TRUE, fig.width=11, fig.height=4, cache=FALSE>>=
load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
peas <- p_boot(things=y-x, 13)
p_star <- sum(peas<=0.05)/100
hist(peas, breaks=seq(0,1,0.05), col=.blue, main="", xlab="P-values") # col=c(.green, rep(.blue, 19)))
tmp <- round(100*p_star)
arrows(x0 = 0.2, x1 = 0.06, y0 = tmp-1)
text(x=0.2, y = tmp-1, pos = 4, cex = 1.5,
     labels = paste0(tmp, "% of p-values below 0.05"))
@
}
\frame{ % -------------------------------------------------------------------->
These 100 'regenerated' $p$-values, suggest that the power was
$\Sexpr{signif(p_star,2)}$.

This is an estimate! (The error will depend on both the resample \emph{and} inital sample.)

<<bootstrap6, echo=FALSE, include=FALSE>>=
load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
set.seed(18870412)
(POW1 <- search(things=y-x, m=c(10,15,20,25,30,35,40,45), bi = 100, mi = 100))
save(list=sprintf("POW%d",1), file="data/power_bm.Rdata")
@
The plot shows a bootstrap estimate for varying sample sizes:
<<bootstrap7, echo=FALSE, include=TRUE, fig.width=11, fig.height=4>>=
load("data/power_bm.Rdata")
names(POW1) <- c("size", "low", "est", "high")
err_guess <- 2*0.5*(1-0.5)/13
POW1$low <- POW1$low - err_guess
POW1$high <- POW1$high + err_guess
ggplot(POW1, aes(size, est, min=low, max=high)) +
    geom_pointrange() +
    geom_point(size=4) +
    labs(x="(Re)Sample size", y="Estimated power") +
    scale_x_continuous(limits=c(0,50)) +
    scale_y_continuous(limits=c(0,1.02), breaks=c(seq(0,0.8,0.2), 0.9, 1)) +
    theme_classic() +
    geom_abline(intercept=0.8, slope=0, lty=2) +
    geom_abline(intercept=0.9, slope=0, lty=3)
@
So you should probably use at least 35 individuals. (There the power is estimated to be at least 80\%.)
}
\frame{ % -------------------------------------------------------------------->
\frametitle{References}
\begin{itemize}
   \item Chapters 23-25: Petrie \& Sabin. \emph{Medical Statistics at a Glance}, Wiley-Blackwell (2009).
\end{itemize}
}
\end{document} % <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


<<"a-kinda-test", eval = FALSE, include = FALSE>>=
## z <- c(1,-2,3,-4,-6,7,11,-12,12,17,24,158,169)
## power.t.test(n = length(z), delta = mean(z), sd = sd(z), type = "one.sample")

load("data/F4_breastfeeding.Rdata"); x <- x[-1]; y <- y[-1]
z <- y - x

t.test(x, y, paired = TRUE)
wilcox.test(x, y, paired = TRUE, exact = FALSE, conf.int = TRUE)

hist(z, breaks = seq(-12.5,175, by =12.5))
mean(z)
median(z)
sd(z)

power.t.test(delta = 29, sd = 60.5, power = 0.8, type = "one.sample")

min(z)
z2 <- log(z+13)-log(13)
t.test(z2)
## 0 --> log(13)
sort(z2)
qqnorm(z2)
hist(z2)

mean(z2)
sd(z2)

power.t.test(delta = mean(z2), sd = sd(z2), power = 0.8, type = "one.sample")

l <- 45
z_test <- log(z+l)-log(l)
t.test(z_test)
power.t.test(delta = mean(z_test), sd = sd(z_test), power = 0.8, type = "one.sample")
@

