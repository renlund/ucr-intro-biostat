<<PRES_OR_HANDOUTS, cache=FALSE, echo=FALSE, include=TRUE, results='asis'>>=
if(!exists("HANDOUT")) HANDOUT <- FALSE
if(HANDOUT){
   cat("
\\documentclass[handout]{beamer}
\\usepackage{pgf,pgfpages}
\\pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=0.5in]
")
} else {
   cat("\\documentclass{beamer}")
}
rm(HANDOUT)
@
\usepackage{beamerthemeclassic}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
<<functions, cache=FALSE, include=FALSE>>=
revsort <- function(sort_x, x_order){
   n <- length(sort_x)
   xx <- rep(NA_real_,n)
   for(k in 1:n){
      xx[x_order[k]] <- sort_x[k]
   }
   xx
}
dotplot <- function(x, skal=100, off=0.1, maxi=1, yfix=1, new=FALSE, ...){
   perm <- order(x)
   xx   <- x[perm]
   n    <- length(xx)
   r    <- diff(range(xx))/skal
   nb   <- rep(0,n)
   y    <- rep(NA_real_,n); y[1] <- yfix
   for(k in 2:n){
      x0 <- xx[-k]
      nb[k] <- length(x0[x0>=xx[k]-r & x0<=xx[k]])
      d <- min(off*nb[k],maxi)
      y[k] <- yfix+runif(1, min=-d, max=+d)
   }
   if(new)
      plot(x=revsort(xx,perm), y=revsort(y,perm), yaxt='n', ylab="", ylim=c(0,2), ...)
   else
      points(x=x, y=revsort(y,perm), ...)
}
.yellow <- wes_palette("Cavalcanti1", 5)[1]
.green <- wes_palette("Cavalcanti1", 5)[2]
.grey <- wes_palette("Cavalcanti1", 5)[3]
.blue <- wes_palette("Cavalcanti1", 5)[4]
.red <- wes_palette("Cavalcanti1", 5)[5]
@

\newcommand{\pr}{\mathbf{Prob}}
\newcommand{\el}{\mbox{\;or\;}}
\newcommand{\rymd}{\vspace{0.3cm}}
\newcommand{\rymda}{\vspace{0.5cm}}
\newcommand{\code}{\texttt}
%\setbeamersize{text margin left=6mm, text margin right=2mm}  % DEFAULT
\setbeamersize{text margin left=3mm, text margin right=2mm}

\title{Introduction to Biostatistics \\ Lecture 1B and 2}
\author{Henrik Renlund}
\date{Fall 2019}

\begin{document} % >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
\frame{ % -------------------------------------------------------------------->
\frametitle{Introduction to Biostatistics}
\begin{center}
\begin{figure}
\includegraphics[scale=0.39]{pics/livinghistogram.jpg}
\end{figure}
\end{center}
\begin{flushright}
{\tiny Arranged by Linda Strausbaugh (Genetics 147:5, 1997)}
\end{flushright}
}
\frame{ % -------------------------------------------------------------------->
\titlepage
\begin{center}
\includegraphics[scale=0.2]{pics/ucrlogo.pdf}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Contents of Lecture 1-2}
\tableofcontents
}
\frame{ % -------------------------------------------------------------------->
\frametitle{What shall we learn today (and tomorrow)?}
\begin{itemize}
   \item Data description
      \begin{itemize}
         \item Graphs
         \item Tables and summary measures
      \end{itemize}
   \item Probability Models
      \begin{itemize}
         \item Glimpse at theory
         \item Normal distribution and some properties
         \item Some properties of samples and the Central Limit Theorem.
      \end{itemize}
\end{itemize}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Descriptions]{Data and descriptive statistics} %%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{Types of data}
A data set contains one or more \emph{variables}, typically arranged as:
\begin{center}\begin{tabular}{cccccc}
\code{Individual} & \code{Gender} & \code{Age} & \code{Albumin} & \code{Diabetes} & \code{Happiness} \\
1 & M & 29 & 3.92 & 0 & {\LARGE $\smile$ } \\
2 & F & 37 & 4.12 & 0 & {\LARGE $\frown$ } \\
3 & F & 25 & 4.75 & 1 & {\LARGE $-\phantom{.}$} \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$
\end{tabular}\end{center}
Theoretical data categories:
\begin{itemize}
   \item Numerical
      \begin{itemize}
         \item discrete; typically integer valued 1, 2, \ldots, like \code{Age}, \emph{or}
         \item continuous; i.e.\ any value in an interval, like \code{Albumin}.
      \end{itemize}
   \item Categorical
      \begin{itemize}
         \item nominal, e.g.\ \code{Gender}, \emph{or}
         \item ordinal, e.g.\ \code{Happiness}: $\frown, -, \smile$.
      \end{itemize}
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{How statisticians spend their time}
In practice data might be stored in the wrong format.

\rymd
\textbf{Check this prior to analysis!}
This is especially important if data has been transferred (between formats, different OS, etc).

\rymd
Common problems:
\begin{itemize}
   \item date- and categorical data suddenly stored as integers
   \item numerical values stored as text (due to ',' vs. '.')
\end{itemize}

\rymd
Usually one only needs to distinguish
\begin{itemize}
   \item measurements (\code{Age}, \code{Albumin} are numerical), and
   \item categories (Gender, \code{Diabetes}, \code{Happiness} are categorical).
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{"Table 1"}
It is useful to provide a summary table of the variables you are working with.
Choice of descriptive measures may be context dependent.
\begin{table}\begin{center}
%\caption{Data set on 84 individuals.}
\begin{tabular}{|l|cc|cc|} \hline
\emph{variable} &  \multicolumn{2}{c|}{\texttt{Diabetes No}} & \multicolumn{2}{c|}{\texttt{Diabetes Yes}}\\
\multicolumn{1}{|r|}{\emph{value}} &  \emph{mean} & \emph{sd}  & \emph{mean} & \emph{sd} \\  \hline %\cline{3-4}
\code{Age}   & 32.0 & 15.9 & 32.5 & 14.1\\
\code{Albumin}  & 4.20 & 0.37 & 3.80 & 0.50\\ \cline{2-5}
   & \emph{percent} & \emph{n} & \emph{percent} & \emph{n} \\ \cline{2-5}
\code{Gender} &&&& \\
\multicolumn{1}{|r|}{M}  & 64\% & 27 & 52\% & 22 \\
 \multicolumn{1}{|r|}{F} & 36\% & 15 & 48\% & 20 \\
\code{Happiness} &&&& \\
\multicolumn{1}{|r|}{$\frown$}   & 61\% & 19 & 36\% & 15 \\
\multicolumn{1}{|r|}{$-$}        & 23\% & 7  & 36\% & 15 \\
\multicolumn{1}{|r|}{$\smile$}   & 16\% & 5  & 36\% & 12 \\ \hline
\end{tabular}
\end{center}\end{table}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Some points on tables (for publication)}
\begin{itemize}
   \item Table and caption should be self contained.
   \item Put captions \emph{above} the table.
   \item Avoid excessive precision. (Mean age 65.63?)
   \item Use adequate measures of location and spread.
   \item Every table should be referred to in text.*
\end{itemize}

\rymda *The table should illustrate some part of the data relating to the hypothesis of the paper. Referring to a table should fit the narrative.

\rymd Generally bad: "Table 3 displays values of biomarkers in group A and B".

\rymd Better: "The mean level of measured biomarkers are higher in group A compared to B (Table 3)."
}
\frame{ % -------------------------------------------------------------------->
\frametitle{What about missing data?}
Missing data is usually a problem for observational studies.

\rymd Typically data is missing in explanatory variables.

\rymd Suppose we investigate death within one year of myocardial infarction with a model that includes gender, age, BMI (some missing) and smoking status (some missing).

\rymd The statistical software default is to include only those individuals with complete case data on all variables that you include.

\rymd \emph{Complete case analysis} will only give an unbiased result if the reason that a variable is missing has nothing to do with the actual value (and/or the outcome).

\rymd If the missing mechanism is known this might be utilized in the analysis.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Solutions\ldots ish}
There is no trick that guarantees a non-biased analysis.

\rymd \textbf{Single imputation} e.g.\ replace missing value with a "typical" value for that variable (e.g. mean or median). This method underestimates the variance in the variable and will give overly optimistic results.

\rymd \textbf{Multiple imputation} create multiple imputed data sets where the
missing values are replaced differently in each iteration (e.g. drawn at random
from the non-missing values).

\rymd
\begin{quote}
"It is not that multiple imputation is so good; it is really that other methods for adressing missing data are so bad."
\begin{flushright}
(Donald Rubin)
\end{flushright}
\end{quote}
\textbf{N.B.} we typically do not impute our outcome data!
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualization of (continuous) data}
A sufficiently small data set might not need visualization.

\rymda
The level of the protein albumin was recorded in a
sample (of size 8) of mice (56 days old):
<<show_albumin, results='asis'>>=
load("data/F3_albumin.Rdata")
out <- paste(alb, collapse="\\quad")
cat("\\[", out, "\\]")
@
(measured in g/dL - this data set will return in lecture 3).

\rymda One simple way to get some handle on data is to order it:
<<show_albumin_sorted, results='asis'>>=
load("data/F3_albumin.Rdata")
out <- paste(sort(alb), collapse="\\quad")
cat("\\[", out, "\\]")
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Dotplot of albumin data}
A dotplot is a one dimensional plot of the data.

\rymd
<<plot_alb, fig.align='center', fig.height=3, fig.width=11>>=
load("data/F3_albumin.Rdata")
par(mar=c(4,7,0,0))
plot(
   x = alb, y = rep(2,8),
   yaxt='n', ylab="", ylim=c(0.8,1.2),
   xlab="g / dL",
   cex.lab=1.2,
   main=""
)
points(sort(alb), rep(1,8))
wtf <- axis(2, at=1, labels=FALSE)
text(
   x=1.75, y=wtf,
   labels=c("dots"),
   cex=1.2,
   xpd=TRUE,
   pos=2,
   offset=0
)
@

If there are non-unique (or close) points, the data set
may appear smaller than it really is.

\rymd This can be alleviated by
\begin{itemize}
   \item perturbation, or,
   \item alpha transparency.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Subarachnoidal bleeding}
A biomarker - the protein S100$\beta$ - was measured for 113 individuals with aneurysmal subarachnoid hemorrhage. (To return in lecture 10.)

\rymd
<<plot_subarach, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,7,0,0))
plot(
   x=dd$s100b, y=rep(3,113),
   ylab="", yaxt='n', ylim=c(0.5,3.2),
   xlab="microgram / litre",
   cex.lab=1.2
)
points(x=dd$s100b, y=rep(2,113), pch = 16, col = rgb(0,0,0,0.4))
dotplot(x = dd$s100b, maxi = 0.5)
wtf <- axis(2, at=1:3, labels=FALSE)
text(
   x=0, y=wtf,
   labels=c("Perturbed\ndots", "Alpha-\ntransparency", "Overlapping\ndots"),
   cex=1.2,
   xpd=TRUE,
   pos=2,
   offset=1
)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Dotplot and groups}
Dotplots can display groups.

\rymd
<<sub_comp, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
x <- dd$s100b[dd$outcome=="Poor"]
y <- dd$s100b[dd$outcome=="Good"]
good_col <- .yellow
bad_col  <- .green
par(mar=c(4,5,0,0))
layout(matrix(1:2,nrow=2))
dotplot( x=dd$s100b, new=TRUE, col=ifelse(dd$outcome=="Good", good_col, bad_col),
         xlab="", maxi=0.6, skal=75)
#legend("bottomright", c("Good", "Poor"), col=c(good_col, bad_col), cex=1.2,
#       lty=NULL, pch=1, title="Outcome", bty='n')
legend(x = -0.14, y = 1.5, c("Good", "Poor"), col=c(good_col, bad_col), cex=1.2,
       lty=NULL, pch=1, title="Outcome", bty='n', xpd = TRUE)
plot(x=dd$s100b,rep(1,113),type='n',xlab="microgram / litre",ylab="",
     yaxt='n', ylim=c(0.5,2.5), cex.lab=1.2)
dotplot(x, col=bad_col, maxi=0.5)
dotplot(y, col=good_col, maxi=0.5, yfix=2)
wtf <- axis(2,at=1:2, labels=FALSE)
text(x=0, y=wtf, labels=c("Poor", "Good"), cex=1.2,
     xpd=TRUE, pos=2, offset=1)
layout(matrix(1,nrow=1))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Percentiles (Measure of location)}
\begin{itemize}
   \item The $k$th percentile is a value $v$ such that $k$ percent of your data lies below (or at) $v$. (Usually not uniquely defined.)

   \rymd \item The 50th percentile (the \emph{median}) is the point which divides your ordered sample equally. (Only 'unique' if sample is odd, else use mean of the two midpoints.)

   \rymd \item \emph{The Quartiles:} Q1 is the 25th percentile, Q2 is the 50th percentile and Q3 is the 75th percentile.

   \rymd \item We can describe all percentiles with the \emph{empirical cumulative distribution function} (ecdf).

   When the sample size is 113 the jumps in the ecdf will be multiples of $1/113\approx 0.01$.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Empirical cumulative distribution function for S100$\beta$}
$\phantom X$
<<subarach_ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,4,0,0))
plot.ecdf(ecdf(dd$s100b),  verticals=TRUE, do.points=FALSE, ylab="",
          xlab="microgram / litre", main="", ylim=c(-0.08,1), cex.lab=1.2)
points(dd$s100b, rep(-0.05,113), pch =16, col = rgb(0,0,0,alpha = 0.4))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Empirical cumulative distribution function}
Ecdf's can also display group differences.
<<subarach_2ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,4,0,0))
plot.ecdf(ecdf(dd$s100b[dd$outcome=="Good"]),  verticals=TRUE, do.points=FALSE,
          xlim=c(0,1.2), main="", xlab="microgram / litre", ylab="", cex.lab=1.2)
plot.ecdf(ecdf(dd$s100b[dd$outcome=="Poor"]),  verticals=TRUE, do.points=FALSE,
          lty=2,add=TRUE)
legend(x=0.9,y=0.4, c("Good", "Poor"), title="Outcome", lty=c(1,2), bty='n', cex=1.2)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{``Average value'' (Measure of location)}
An average value is a single value meant to be
representative of the entire data set.

\begin{itemize}
\item  \textbf{The mode:} is the single most common value of a data point. \\
(Mostly meaningful for categorical data.)

\rymd
\item  \textbf{The median:} is the midpoint of the ordered numerical sample.

\rymd
\item  \textbf{The mean:} is the "center of gravity" of a data set. \\
Note: unlike the median, the mean value is sensitive to "extreme" values.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Mean or median?}
Ex: A small company has 5 employees, who earns 19, 21, 22, 24, 27 (K SEK)
and a boss who earns 55.
\begin{center}
\begin{tabular}{|c|cc|} \hline
Salaries       & Employees & Entire company \\ \hline
Median & 22   & 23 \\
Mean   & 22.6 & 28 \\ \hline
\end{tabular}
\end{center}

\vspace{0.5cm}
Some points:
\begin{itemize}
   \item Small data sets might not  need summary measures.
   \item Symmetric data has mean $\approx$ median.
   \item (Easy enough to calculate both.)
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Measuring the spread of a data set}

\begin{itemize}
   \item  \textbf{Range} The difference between the maximum and the minimum value.

   \item  \textbf{Interquartile range (IQR)}: Q3-Q1.

   \item \textbf{Standard deviation (sd)} is given by the formula,
   \[ s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar x)^2}. \]
   %It is a measure of spread with expressed in the same unit as the data.
   Where $x_1, x_2, \ldots, x_n$ is the sample  and
   \[ \bar x=\frac 1n\sum_{i=1}^n x_i \] is the (sample) mean.

   \rymd It is (approximately) the mean distance to the mean value.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Boxplot of S100$\beta$}
The boxplot usually show min, Q1, med, Q3 and max (the "5-point summary")\ldots
<<sub_box_1, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,1,0,0))
dotplot(dd$s100b, new=TRUE, col="grey60", xlab="microgram / litre", cex.lab=1.2)
boxplot(dd$s100b, horizontal=TRUE, boxwex=2, range=0, add=TRUE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Boxplot}
\ldots but most software mark points that are more than
1.5 times the IQR away from 'the box'.
<<sub_box_2, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,1,0,0))
boxplot(dd$s100b, horizontal=TRUE, boxwex=1,
        xlab="microgram / litre", cex.lab=1.2)
#axis(2, at=seq(0,2,0.1))
qs <- quantile(dd$s100b)
t_s <- 1.2
arrows(x0=qs[2], x1=qs[4], y0=0.7,y1=0.7, code=3)
text(x=(qs[2]+qs[4])/2, y=0.7, pos=1, "IQR", cex=t_s )
p0 <- 2.5*qs[4]-1.5*qs[2]
arrows(x0=qs[4], x1=p0, y0=.8, y1=.8,code=3)
abline(v=p0, lty=2, col="grey60")
text(x=(qs[4]+p0)/2, y=0.8, pos=1, "1.5*IQR", cex=t_s)
text(x=(p0+max(dd$s100b))/2, y=0.75,pos=1, "'Outliers'", cex=t_s)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Connection between boxplot and ecdf}
The boxplot contains less information.
<<sub_box_ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,3,0,0))
plot.ecdf(ecdf(dd$s100b),  verticals=TRUE, do.points=FALSE, ylab="",
          xlab="microgram / litre", main="", yaxt='n', cex.lab=1.2)
axis(2, at=seq(0,1,0.25))
abline(h=c(0.75,0.25), lty=2, col="grey60")
boxplot(dd$s100b, add=TRUE, horizontal=TRUE, at=0.5, boxwex=1, lwd=2)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Pattern or detail?}
Here is fake data whith 7 subgroups (a-g).

<<multiple-ecdf-vs-boxplots, include = TRUE, fig.heigth = 8>>=
m <- 7; n <- 50
set.seed(19791224)
x <- factor(rep(letters[1:m], each = n))
s <- rep(runif(m), each = n)
y <- rnorm(n * m, as.numeric(x) + 5, 3 * (s + .1))
layout(matrix(1:2, nrow = 2))
par(mar=c(1,5,0,0))
boxplot(y ~x, horizontal = TRUE, ylim = c(3, 20), xaxt = 'n', ylab = "Groups")
te <- tapply(y, x, ecdf)
par(mar=c(2,5,0,0))
plot(te[[1]], main = "", verticals = TRUE, do.points = FALSE, xlim = c(3, 20), xlab = "", ylab = "Ecdf:s")
for(k in 2:m) plot(te[[k]], verticals = TRUE, do.points = FALSE, add = TRUE, lty = k)
layout(matrix(1, nrow = 1))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Advanced graphics\ldots}
Anyone seriously interested in graphics might want to look at Wilkinson's \emph{The Grammar of Graphics}, which provides a framework for thinking about data visualization. These ideas are implemented in the R package \textbf{ggplot2} - which provides tools for mapping variables to aestic properties, adding layers of statistical computations, faceting, etc.

<<ggplot2-promotion, include = TRUE>>=
mtcars$am <- as.logical(mtcars$am)
mtcars$vs <- factor(mtcars$vs, labels = c("V engine", "Straight engine"))
ggplot(mtcars, aes(disp, mpg)) +
   geom_point(aes(shape =  factor(am), color = factor(gear), size = qsec)) +
   geom_smooth(method = "lm", color = "black") +
   facet_wrap(~vs, nrow = 2, scales = "free_y") +
   scale_color_manual(values = wes_palette("Cavalcanti", 5)[c(1,2,5)], name = "Gears") +
   scale_size(range = c(3,12), name = "Mile time") +
   scale_shape_discrete(name = "Manual") +
   labs(x = "Miles per Gallon", y = "Displacement") +
   theme_bw()
@


}
\frame{ % -------------------------------------------------------------------->
\frametitle{Some points on graphs (for publication)}
\begin{itemize}
   \item Graph and caption should be self-contained.
   \item Every graph should be referred to in the text.
   \item 'Economy' Do not make a graph which is more easily expressed in text or a small table. \\ E.g. graph with a single boxplot.
   \item Pattern or detail? \\ E.g.
      \begin{itemize}
         \item a ecdf gives a lot of detail of a data set. \\
         \item graph with multiple boxplots can reveal pattern among subgroups.
      \end{itemize}
   \item Avoid 2D graphs shown in 3D.
   \item Avoid pie charts? It depends\ldots
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{In defense of pie charts?}
<<pie, include=FALSE, fig.height=5, fig.width=5, fig.keep = TRUE>>=
set.seed(20180927)
x <- sample(LETTERS[1:5], size = 250, replace = T, prob = c(5,2,1,4,3))
a_table <- table(x); save(a_table, file="data/a_table.rdata")
barchart(a_table, col = wes_palette("Cavalcanti1", 5))
pie(a_table, col = wes_palette("Cavalcanti1", 5))
@
Is it of interest to be able to compare summation of levels?

(Is A + B + C smaller than D + E?)

<<show_pie, results='asis', cache = FALSE>>=
plot_code <- sprintf("\\includegraphics[scale=0.47]{figure/%s}\n", paste0("pie-",1:2))
cat(plot_code, sep="")
@
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Models]{Probability theory and models} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{ % -------------------------------------------------------------------->
\textbf{Probability} theory studies models of random data. A \textbf{model} is a way of specifying the range of possible values and the probability with which these occur.
\begin{itemize}
   \item \textbf{Probability functions} describe discrete numeric/categorical data
   \item \textbf{Density functions} describe continuous (numeric) data
\end{itemize}

\rymd The \textbf{cumulative distribution function} is a universal way of describing all random (numeric) data. (Will not be discussed.)

\begin{itemize}
   \item \textbf{Probability theory:} given model (model parameters, or other aspects) - describe how data behave. E.g.\
   \begin{itemize}
      \item specific results: how likely are specific deviations
      \item general results: Law of Large Numbers, Central Limit Theorem, etc.
   \end{itemize}
   \item \textbf{Inference theory:}  given data what is a likely model/parameters or other aspects of the underlying distribution (without specifying model = non-parametric statistics).
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Probability models for categorical or integer-valued data}
A yet undetermined random value is called a \emph{random variable} (RV).

\rymd Let $Z=$'the outcome of the throw of a die'.
Then $\pr(Z=k)=1/6$ for all $k=1,2,\ldots,6$, or, equivalently

\begin{center}\begin{tabular}{|c|cccccc|} \hline
Value $k$ & 1  & 2 & 3 & 4 & 5 & 6 \\
$\pr(Z=k)$ & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\ \hline
\end{tabular}\end{center}

\rymd Suppose that in the population there are 49 \% non-smokers, 20 \% former smokers
and 31\% current smokers. Then the smoking status $X$ of a person selected
at random is a RV with a probability function

\rymd
\begin{center}\begin{tabular}{|c|ccc|} \hline
Value $v$  & non  & former & current \\
$\pr(X=v)$ & 0.49 & 0.20   & 0.31 \\ \hline
\end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->
Five samples from three different sampling sizes from previous distribution
<<fig.height = 7>>=
set.seed(20101212)
pf <- c(0.49,0.20,0.31)
m <- 5
values <- c("non", "former", "current")

foo_bar <- function(n, l = FALSE){
   # n <- 30
   s <- factor(sample(values, size = m*n, replace = TRUE,
                      prob = pf), levels = values)
   g <- rep(sprintf("%d",1:m), each = n)
#    barplot(pf, width = m, border = "black", col = "black",
#            density = 9, ylim = c(0,0.7), lwd = 2, angle = +45, main = paste0("Sample size ", n))
   barplot(prop.table(table(g, s),1), col = wesanderson::wes_palette("Cavalcanti", 5),
           beside = TRUE, legend = l,  ylim = c(0,0.7), main = paste0("Sample size ", n),
           args.legend = list(x="topright", title = "Sample", horiz = TRUE))
   barplot(pf, width = m, border = "black", col = "black",
           density = 15, lwd = 2, angle = +45, add = TRUE)
}

par(mar=c(4,5,2,1))
layout(matrix(1:4, nrow = 2, byrow = TRUE))
barplot(pf, width = m, names.arg = values, border = "black", col = "black", ylim = c(0,0.7),
        main = "True distribution", density = 15, lwd = 2, angle = +45) ## legend = l2,
foo_bar(25)
foo_bar(100)
foo_bar(1000, l = TRUE)
layout(matrix(1, nrow = 1))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{FEV data set}
430 children (9-17 years of age) had their age, forced expiratory volume
in 1 second (FEV) and smoking status (!) recorded. (To be seen again
in lecture 9.)

\rymd A barchart is a way to visualize a variable with a small number
of unique values (often categorical). They are visual analogous
of tables.

\rymd Ex: how do the ages distribute over smoking status?
<<tab_smoker, results='asis'>>=
load("data/F8_smoking.Rdata") # dd
with(dd, tabsmok <<- table( age=age, smoker=smoker))
latex(
   object = t(tabsmok),
   file = "",
   title = "Smoking",
   cgroup = "Age"
)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualizing 'age' versus 'smoking'}
<<smoker>>=
load("data/F8_smoking.Rdata")
par(mar=c(4,4,0,0))
barplot(tabsmok, beside=TRUE, legend=TRUE, ylab="Frequency", col=brewer.pal(9, "YlGn"))
@
}
\frame{ % -------------------------------------------------------------------->
%\frametitle{}
If the groups (smokers/non-smokers) aren't balanced
it is difficult to compare the distributions.

Tabulate/plot the percentages within groups:
<<tab_smoker2, results='asis'>>=
load("data/F8_smoking.Rdata") # dd
with(dd, tabsmok2 <<- addmargins(prop.table(table( age=age, smoker=smoker), 2), 1))
latex(
   tabsmok2,
   digits=2,
   file="",
   title="Age",
   cgroup="Smoking (\\%)"
)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualizing 'age' versus 'smoking' as percentages within smoking groups}
<<plot_smoker2>>=
load("data/F8_smoking.Rdata")
with(dd, tabsmok3 <<- 100*prop.table(table( age=age, smoker=smoker), 2))
par(mar=c(4,4,1,0))
barplot(tabsmok3, beside=TRUE, legend=TRUE, ylab="Percent", col=brewer.pal(9, "YlGn"))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualizing 'smoking' versus 'age' as percentages within age groups, stacked}
<<plot_smoker3>>=
load("data/F8_smoking.Rdata")
dd$age <- factor(dd$age)
ggplot(dd, aes(age, fill=smoker)) +
   geom_bar(position="fill") +
   labs(x="Age", y="Percentage within year") +
   scale_fill_manual(values=c(.blue, .yellow), name="Smoker") +
   theme_classic()  +
   scale_y_continuous(breaks = seq(0, 1, by = 0.25), labels = sprintf("%s%%",seq(0,100,by=25)))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Probability model for continuous data}
Recall that a RV is a yet undetermined value among several possible numbers.

A continuous RV is described by its \emph{density function}.

\includegraphics[scale=0.31]{pics/density_function.png}

If $X$ has density function $f$ as above, then we compute probabilities as
\[ \pr( a\leq X \leq b)=\;\mbox{Area(a,b)}. \]
}
\frame{ % -------------------------------------------------------------------->
The shape of a histogram estimates the shape of the density function.
<<test-hist, fig.height = 4>>=
load("data/F8_smoking.Rdata")
# h <- hist(dd$fev, plot = FALSE)
par(mar=c(4,5,2,1))
z <- 1.5
u <- z
layout(matrix(1:3, nrow = 1))
hist(dd$fev, main = "", xlab = "FEV (L)", ylab = "Count", col=.blue, cex.axis = z, cex.lab = u)
hist(dd$fev, freq = FALSE, main = "", xlab = "FEV (L)", yaxt = 'n', ylab = "Percent", col=.blue, cex.axis = z, cex.lab = u)
vid <- seq(0,0.5,0.1); axis(2, at = vid, labels = sprintf("%d%%", .5*100*vid), cex.axis = z)
hist(dd$fev, freq = FALSE, main = "", xlab = "FEV (L)", col=.blue, cex.axis = z, cex.lab = u)
# b <- c(1,2,2.5,3,3.5,4,6)
# h2 <- hist(dd$fev, plot = FALSE, breaks = b)
# h2_mod <- h2
# h2_mod$density <- h2$density * diff(h2$breaks)
# plot(h2_mod, main = "", xlab = "FEV (L)", col=.blue, ylab = "Percent")
# hist(dd$fev, breaks = b, main = "", xlab = "FEV (L)", col=.blue)
layout(matrix(1,nrow = 1))
@
"Density" is more abstract but
\begin{itemize}
   \item gives right scale for density function estimate (easy to correctly plot candidate model on top of histogram)
   \item allows for varying "bins"
   \item allows for comparison between very different sample sizes
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Histogram (with density) of FEV}
The histogram (with density on the y-axis) estimates the density function.
<<fev2>>=
load("data/F8_smoking.Rdata")
h0 <- hist(dd$fev, plot=FALSE)
par(mar=c(4,4,0,0))
h <- hist(dd$fev, freq=FALSE, ylim=c(0,1.05*max(h0$density)),
          xlab="FEV (L)", main="", col=.blue) # col="grey80")
text(h$mids, h$density,labels=paste0(round(100 * h$counts/sum(h$counts),1), "%"),pos=3)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Histogram of FEV}
The interval width is arbitrary\ldots
<<fev3>>=
load("data/F8_smoking.Rdata") # dd
h <- hist(dd$fev, plot=FALSE)
par(mar=c(4,4,0,0))
h1 <- hist(dd$fev, freq=FALSE, breaks=seq(1,6,1), ylim=c(0,1.05*max(h$density)),
           xlab="FEV (L)", main="", col=.blue) #col="grey80")
text(h1$mids, h1$density,paste0(round(100 * h1$counts/sum(h1$counts),1), "%"),pos=3)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Histogram of FEV}
\ldots and could be varying.
<<fev4>>=
load("data/F8_smoking.Rdata") # dd
#h <- hist(dd$fev, plot=FALSE)
par(mar=c(4,4,0,0))
h2 <- hist(dd$fev, freq=FALSE, breaks=c(1,2,2.5,2.75,3,3.5,4,6),
           ylim=c(0,1.05*max(h$density)), xlab="FEV (L)", main="", col=.blue) #col="grey80")
text(h2$mids, h2$density,paste0(round(100 * h2$counts/sum(h2$counts),1), "%"),pos=3)
@
}
%' \frame{ % -------------------------------------------------------------------->
%' \frametitle{Histograms with counts}
%' The scale of histograms with counts depends on chosen interval width and sample size. Below is the FEV data set with different widths.
%'
%' <<fev5>>=
%' load("data/F8_smoking.Rdata") # dd
%' layout(matrix(1:2,nrow=1))
%' h1 <- hist(dd$fev, plot=FALSE, breaks=seq(1,6,1))
%' par(mar=c(4,4,0,0))
%' hist(dd$fev, freq=TRUE, breaks=seq(1,6,1), ylim=c(0,1.05*max(h1$counts)),
%'            xlab="FEV (L)", main="", col=.blue)
%' hist(dd$fev, freq=TRUE, ylim=c(0,1.05*max(h1$counts)),
%'           xlab="FEV (L)", main="", col=.blue)
%' layout(matrix(1,nrow = 1))
%' @
%' }
\frame{ % -------------------------------------------------------------------->
\frametitle{Summary}
\begin{center}
\begin{tabular}{|c|c|p{5cm}|} \hline
Graph & Summary Measure & Theory \\ \hline \hline
Ecdf & percentiles & (Cdf) \\ \hline
Boxplot & min, Quartiles, max & \\ \hline
Bar charts & & Probability functions (discrete RV) \\ \hline
Histograms & & Density functions (continuous RV)\\ \hline
& median, IQR & any distribution\\ \hline
& mean, s.d. & symmetrical distribution ($\approx$ Normal distribution) \\ \hline
\end{tabular}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{The Normal Distribution}
Sometimes we assume that the population follows a Normal density curve.
<<fev6>>=
load("data/F8_smoking.Rdata") # dd
n <- 11
par(mar=c(4,4,0,0))
h0 <- hist(dd$fev, plot=FALSE)
curve(dnorm(x,mean(dd$fev), sd(dd$fev)), from=1, to=6, lwd=2,ylim=c(0,1.05*max(h0$density)), ylab = "Density", xlab  = "FEV (L)")
hist(
   dd$fev,
   freq=FALSE,
   ylim=c(0,1.05*max(h0$density)),
   xlab="FEV (L)",
   main="",
   col=.blue, #col="grey80",
   breaks=seq(1,6,length.out=n),
   add = TRUE
)
curve(dnorm(x,mean(dd$fev), sd(dd$fev)), from=1, to=6, lwd=2, add =TRUE, lty = 2)
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{Properties of the standard Normal distribution \\ (and why you need to know the number 1.96)}
The standard Normal distribution has a standard deviation of 1. \\
68\% of the 'probability mass' lies within $\pm 1$. \\
95\% of the 'probability mass' lies within $\pm 1.96$.
<<normal_stuff, fig.width=5, fig.height=5, include=FALSE>>=
x <- seq(-3.5,3.5,length.out=100)
y <- dnorm(x, 0, 1)
plot( c(-3.2,3.2),c(0,0.4), col="white",
      main="",ylab="Density",xlab="")
v <- qnorm(0.975)
xx <- seq(-v,v,length.out=100); yy <- dnorm(xx,0,1); xx <- c(xx[1],xx,xx[100]); yy <- c(0,yy,0)
polygon( xx,yy,  lty=2, col=.blue) # col="lightblue",
points( c(-v,-v), c(0,0.28), type='l', lty=2)
text( -v, 0.3, label=paste("-",signif(v,3),sep=""), cex=1.5 )
points( c(v,v), c(0,0.28), type='l', lty=2)
text( v, 0.3, label=paste("+",signif(v,3),sep=""), cex=1.5 )
points( x,y, type='l', lwd=2)
text( 0,0.15, "95%",cex=2)
x <- seq(-3.5,3.5,length.out=100)
plot( c(-3.2,3.2),c(0,0.4), col="white",
      main="",ylab="Density",xlab="")
v <- 1; #1-2*(1-pnorm(1))
xx <- seq(-v,v,length.out=100); yy <- dnorm(xx,0,1); xx <- c(xx[1],xx,xx[100]); yy <- c(0,yy,0)
polygon( xx,yy, col=.blue, lty=2) # col="lightblue"
points( c(-v,-v), c(0,0.33), type='l', lty=2)
text( -v, 0.34, labels=paste("-",signif(v,3),sep=""), cex=1.5 )
points( c(v,v), c(0,0.33), type='l', lty=2)
text( v, 0.34, labels=paste("+",signif(v,3),sep=""), cex=1.5 )
points( x,y, type='l', lwd=2)
text( 0,0.15, "68%",cex=2)
@

<<plot_code_normal_stuff, results='asis', cache = FALSE>>=
plot_code <- sprintf("\\includegraphics[scale=0.47]{figure/%s}\n", paste0("normal_stuff-",1:2))
cat(plot_code, sep="")
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{The Normal distribution N$(\mu,\sigma)$}
is determined by its mean ($\mu$) and standard deviation ($\sigma$). \\
If $X$ is N(0,1) then $\mu+\sigma X$ is N$(\mu,\sigma)$.
<<normals>>=
n <- 100
x <- seq(-3,8,length.out=n)
y0 <- dnorm(x, 0, 1)
y1 <- dnorm(x, 4.5, 1)
y2 <- dnorm(x, 3, 3)
y3 <- dnorm(x, 1, 2)
m <- max(c(y1,y2,y3))
plot( 0, 0, col="white",ylim=c(0,m),xlim=c(-2,7),xlab="",ylab="Density")
points(x, y0, lty = 2, type = "l")
myCol <-  c(.blue, .green, .yellow) #brewer.pal(3,"Set2")
for(k in 1:3){
   points( x, get( paste("y",k,sep="") ), type='l', col=myCol[k], lwd=3)
}
text( -1, 0.35, "N(0,1)", cex = 1, col = "lightgrey")
text( 2.4, 0.35, "N(4.5,1)", col=myCol[1], cex=2)
text( 1, 0.05, "N(3,3)", col=myCol[2], cex=2)
text( -1, 0.2, "N(1,2)", col=myCol[3], cex=2)
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{Properties of the Normal distribution}
If $X$ is N$(\mu,\sigma)$, then 95\% of observations will
be between $\mu-1.96\sigma$ and $\mu+1.96\sigma$.
<<plot_N_properties>>=
Mu <- 6
Sd <- 2.5
x <- seq(Mu-3*Sd,Mu+3*Sd,length.out=100)
y <- dnorm(x, Mu, Sd)
plot( c(Mu-2.8*Sd,Mu+2.8*Sd),c(0,0.25), col="white",
      main="",ylab="Density",xlab="")
v <- qnorm(0.975)
xx <- seq(Mu-v*Sd,Mu+v*Sd,length.out=100)
yy <- dnorm(xx,Mu,Sd)
xx <- c(xx[1],xx,xx[100])
yy <- c(0,yy,0)
polygon( xx,yy, col=.blue, lty=2) # col="lightblue"
points( c(Mu-v*Sd,Mu-v*Sd), c(0,0.14), type='l', lty=2)
text( Mu-v*Sd, 0.17, labels=paste0(round(Mu-v*Sd, 2), " ="), cex=1.5 )
text( Mu-v*Sd, 0.15, labels=paste(Mu,"-",signif(v,3),"*",Sd,sep=""), cex=1.5 )
points( c(Mu+v*Sd,Mu+v*Sd), c(0,0.14), type='l', lty=2)
text( Mu+v*Sd, 0.17, labels=paste0(round(Mu+v*Sd, 2), " ="), cex=1.5 )
text( Mu+v*Sd, 0.15, labels=paste(Mu,"+",signif(v,3),"*",Sd,sep=""), cex=1.5 )
points( x,y, type='l', lwd=2)
text( Mu,0.10, "95%",cex=2)
text(Mu, 0.23, paste("N(",Mu,",",Sd,")",sep=""), cex=2.2 )
@
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Sampling]{Sampling, SE(M) and CLT.} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<samp_setup, cache=FALSE, include=FALSE>>=
par(mar=c(5,4,4,2)+0.1)
set_params <- function(){
   set.seed("19790424")
   Mu <<- 179
   Sd <<- 6.35
   sampleN <<- function(n) rnorm(n, mean=Mu, sd=Sd)
   x1 <<- sampleN(10)
   x2 <<- c(x1, sampleN(40))
   x3 <<- c(x2, sampleN(450))
   Min <<- min(160, min(x3))
   Max <<- max(200, max(x3))
   B <<- seq(from=145,to=215,by=2.5)
   B2 <<- seq(from=145,to=215,by=1.25)
   yMax <<- max(
      hist(x1, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density,
      hist(x2, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density,
      hist(x3, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density
   )
   n <<- 10
   m <<- 5
   d <<- 0.3
   DD <<- 1.5
   COL <<- "black" # "red"
   alfa <<- 255
   wes_rgb <<- c(
      rgb(216, 183, 10,  alpha = alfa, maxColorValue = 255),
      rgb(2,   64,  27,  alpha = alfa, maxColorValue = 255),
      rgb(162, 164, 117, alpha = alfa, maxColorValue = 255),
      rgb(129, 168, 141, alpha = alfa, maxColorValue = 255),
      rgb(151, 45,  21,  alpha = alfa, maxColorValue = 255)
   )
}
@
\frame{ % -------------------------------------------------------------------->
\frametitle{Attempt to visualize sampling from a given model}

\rymd Assume that height of individuals in some population
\begin{itemize}
   \item is Normally distributed,
   \item has mean ($\mu$) 179 (cm), and,
   \item has s.d. ($\sigma$) 6.35 (cm).
\end{itemize}

\rymd The following three slides show histogram of samples of sizes 10, 50 and 500, respectively.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{$n=10$}
<<samp1>>=
set_params()
curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,
      xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
points(x=x1,y=rep(-0.005, length(x1)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
hist(x1, add=TRUE, prob=TRUE, breaks=B, col=.blue)
curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{$n=50$}
<<samp2>>=
set_params()
curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,
      xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
points(x=x2,y=rep(-0.005, length(x2)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
hist(x2, add=TRUE, prob=TRUE, breaks=B, col=.blue)
curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{$n=500$}
<<samp3>>=
set_params()
B <- seq(from=145,to=215,by=2.5)
curve(dnorm(x, mean=Mu, sd=Sd), from=Min, to=Max,
      xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
points(x=x3,y=rep(-0.005, length(x3)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
hist(x3, add=TRUE, prob=TRUE, breaks=B, col=.blue)
curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Properties of samples and sample means}
Suppose we have a sample of size 10 from the population.

\rymd We want to know the \emph{population mean} ($\mu$).

\rymd We can estimate with the \emph{sample mean}($\mu^*$).

\rymd But how good a guess is $\mu^*$?

Well\ldots if the sample is drawn at random\footnote{All possible samples are equiprobable} then $\mu^*$ is \emph{unbiased} (on average correct).

\rymd  \emph{If we knew} that the sd of $\mu^* = 180$ was, say 3.0, then there is an
(approximate!) interpretation.
\begin{quotation}
The estimated value 180 (cm) is on average off by 3.0  (cm).
\end{quotation}

But what \emph{is} the standard deviation of a sample mean?

\rymd Consider several iterations of the procedure of drawing a sample of size 10.
}
\frame{ % -------------------------------------------------------------------->
%\frametitle{Properties of samples and sample means}
<<sd>>=
set_params()
use.sd.here <- FALSE
MAT <- matrix( rnorm(n*m, mean=Mu, sd=Sd), ncol=n, nrow=m )
save(MAT, file="data/MAT.rdata")
if(use.sd.here) par(mar=c(5, 7, 4, 2)) else par(mar=c(5,4,4,2) + 0.1) # default c(5,4,4,2) + 0.1
plot( x=c(min(MAT), max(MAT)), y=c(0,m), type='n',
      xlab="Outcome", ylab="", yaxt='n', bty='o', xaxt = 'n',
      main=paste(m, "samples of size", n, "with population mean =", Mu, "and sd. = ", Sd)
)
axis(1, at = c(170,179,190))
abline(v=179, lty=2, col="darkgray", lwd=2)
if(use.sd.here) text(x=min(MAT)-DD, y=m+0.5, labels="Sample s.d.", xpd=TRUE, pos=2, offset=1)
for(k in 1:m){
   tmp <- MAT[k,]
   #col <- if(m<=5) wes_palette("Cavalcanti", 5)[k]
   col <- if(m<=5) wes_rgb[k]
   mtm <- mean(tmp)
   sdt <- sd(tmp)
   if(use.sd.here) text(x=min(MAT)-DD, y=m+1-k, labels=round(sdt,1), xpd=TRUE, pos=2, offset=1)
   points(x=tmp, y=rep(m+1-k,n), pch=20+k, bg=col, cex = 1.5)
}
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Properties of sample means}
We can see that samples and their means and
standard deviations vary (of course).

\rymd \textbf{Standard Error of the Mean (SEM)}\\
The standard deviation of the sample mean is referred to
as SEM and a measure
of (approx.) the average distance the population mean.
Thus a measure of 'how good' the sample mean is as
an estimator of the population mean.

\rymd In a Normal model the SEM is the population s.d. dived
by $\sqrt n$.

\rymd The next slide tries to visualize this.
}
\frame{ % -------------------------------------------------------------------->
%\frametitle{Properties of samples and sample means}
<<sem>>=
load(file="data/MAT.rdata")
set_params()
par(mar=c(5, 7, 4, 2) )# default c(5,4,4,2) + 0.1
plot( x=c(min(MAT), max(MAT)), y=c(0,m), type='n',
      xlab="Outcome", ylab="", yaxt='n', bty='o', xaxt = 'n',
      main=paste(m, "samples of size", n, "with population mean =", Mu, "and sd. = ", Sd)
)
axis(1, at = c(170,179,190))
abline(v=179, lty=2, col="darkgray", lwd=2)
text(x=min(MAT)-DD, y=m+0.5, labels="Sample s.d.", xpd=TRUE, pos=2, offset=1)
for(k in 1:m){
   tmp <- MAT[k,]
   #col <- if(m<=5) wes_palette("Cavalcanti", 5)[k]
   col <- if(m<=5) wes_rgb[k]
   mtm <- mean(tmp)
   sdt <- sd(tmp)
   text(x=min(MAT)-DD, y=m+1-k, labels=round(sdt,1), xpd=TRUE, pos=2, offset=1)
   points(x=tmp, y=rep(m+1-k,n), pch=20+k, bg=col, cex = 1.5)
   points(x=mtm, y=m+1-k, cex=3, bg=col, pch=20+k, lwd=2)
   points(x=mtm, y=0, cex=3, bg=col, pch=20+k, lwd=2)
   segments(x0 = mtm, y0 = 0.3, x1 = mtm, y1 = m+0.7-k, col = col, lty = 2)
}
tmp <- rowMeans(MAT)
mtm <- mean(tmp)
text(x=min(MAT)-DD, y=0, labels=paste("SEM ~",round(sd(tmp),1)), xpd=TRUE, pos=2, offset=1, col=COL, cex=1.2)
@
}
\frame{ % -------------------------------------------------------------------->
<<pop_and_mean>>=
set_params()
curve(dnorm(x,Mu,Sd), from=min(MAT),to=max(MAT), ylim=c(0,0.20), ylab="Density",
      xlab="", lty=1, lwd=2, xaxt = 'n')
axis(1, at = c(170, 179, 190))
curve(dnorm(x,Mu,Sd/sqrt(10)), from=165,to=195, add=TRUE, lty=2, lwd=2)
legend("topleft",
       legend=c(expression(N(mu, sigma) - population),
                expression(N(mu,sigma/sqrt(10)) - `sample mean`),
                expression(mu==`179.0`,sigma==6.35)),
       title="Distribution of:", lty=c(1:2,0,0), lwd=c(2,2,0,0), bty='n', cex=1.5)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Normal population $\Rightarrow$ Normal mean}
On the previous slide you saw
\begin{itemize}
   \item a Normal population curve, and
   \item the Normal curve for the sample mean (for sample size 10).
\end{itemize}

\rymd
In this case this is the true (derived from theory) density
curve for the sample mean.

\rymd
Properties of the Normal distribution will aid further analysis
using the mean of the sample.

\rymd
What happens if the population follows some non-Normal
curve?
}
\frame{ % -------------------------------------------------------------------->
\frametitle{The Central Limit Theorem (CLT)}

\textbf{CLT:} Regardless of the true population
density curve, the sample mean density can be made (with arbitrarily
good approximation) Normal by choosing $n$ large enough.

\begin{itemize}
   \item How large does $n$ have to be? \\Depends on how skew the population density is. \\
      \begin{itemize}
         \item In general $n=20$ will suffice.
         \item If population is Normal then $n=1$ is enough.
      \end{itemize}
   \item CLT applies to many 'statistics' (= functions of samples).
\end{itemize}
}

\frame{ % -------------------------------------------------------------------->
\frametitle{Visualization of sample mean from normal population}
The distribution of sample means from a \emph{normal} distribution.
<<norm_mean>>=
COL <- wes_palette("Cavalcanti1", 5) #brewer.pal(5, "Set2")
par(mar=c(4,4,1,1))
plot(1,1,type='n', xlim=c(0,2.5), ylim=c(0,1.8), xlab="Outcome", ylab="Density")
ns <- c(1,2,5,10,20)
for(k in 1:5){
   n <- ns[k]
   curve(dnorm(x, mean=1, sd = 1/sqrt(n)), from=-.5, to=5, add=TRUE, lty=k, col=COL[k], lwd=2)
}
abline(v=1, col="grey", lwd=1, lty=1)
legend("topright", legend=c("1 (Population)", ns[-1]), col=COL, lwd=2, lty=1:4, title="Sample size", bty='n', cex=1.5)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Attempt to visualize CLT for the sample mean}
The distribution of sample means from a skewed distribution.
<<exp_mean>>=
COL <- wes_palette("Cavalcanti1", 5) #brewer.pal(5, "Set2")
par(mar=c(4,4,1,1))
plot(1,1,type='n', xlim=c(0,2.5), ylim=c(0,1.8), xlab="Outcome", ylab="Density")
ns <- c(1,2,5,10,20)
for(k in 1:5){
   n <- ns[k]
   curve(n*dgamma(x*n, shape=n), from=0, to=5, add=TRUE, lty=k, col=COL[k], lwd=2)
}
abline(v=1, col="grey", lwd=1, lty=1)
legend("topright", legend=c("1 (Population)", ns[-1]), col=COL, lwd=2, lty=1:4, title="Sample size", bty='n', cex=1.5)
@
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Visual tests]{Visual tests (of normality)} %%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{Quantiles?}
Quantiles divides your data into (roughly) equal piles.
\begin{itemize}
\item the median is the 2-quantile
\item the tertiles are the 3-quantiles (the $33\frac 13$ percentile and
the $66\frac 23$ percentile)
\item the quartiles (Q1, Q2 and Q3) are the 4-quantiles.
\item \ldots and so on.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Cross-over data (from lecture 4)}
13 patients had their peak expiratory flow (PEF, l/min) recorded
once after inhaling each of two different asthma drugs
(the order of which were random).

\rymda In \emph{paired} data one usually look at the 13 differences as a measurement
of differences in individual effect size.

\rymda Data:
\[ \mbox{\Sexpr{load("data/F4_crossover.Rdata"); paste(y-x, collapse=",\\,\\,")}} \]
Is the normal distribution a good model for these 13 numbers?
}
\frame{ % -------------------------------------------------------------------->
\frametitle{PEV}
A histogram with best normal density fit.
<<pev_h, cache=FALSE>>=
load("data/F4_crossover.Rdata")
par(mar=c(4,4,0,0))
curve( dnorm(t, mean(y-x), sd(y-x)), from=-60, to=160, ylim=c(0,.016), lty=1, xname="t", xlab="Differences (formoterol-sabutamol) L/min", main="", ylab = "Density", xlim = c(-50, 150))
hist(y-x, freq=FALSE, breaks=seq(-50,150,len=10),  xlim=c(-60,160), ylim=c(0,.018),  col=.blue, add = TRUE)
curve( dnorm(t, mean(y-x), sd(y-x)), from=-50, to=150, lty=2, add=TRUE, xname="t")
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{PEV}
A empirical cdf with best normal density cdf.
<<pev_ecdf>>=
load("data/F4_crossover.Rdata")
par(mar=c(4,3,0,0))
plot(ecdf(y-x), verticals=TRUE, do.points=FALSE,
     xlab="Differences (formoterol-sabutamol) L/min", ylab="",
     xlim=c(-100,200), main="")
curve( pnorm(t, mean(y-x), sd(y-x)), from=-250, to=200, lty=2, add=TRUE, xname="t")
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{The Quantile-Quantile plot}
If the differences in effect size is sampled from a Normally distributed population
its QQ-plot should be a straight line (approximately).

A QQ-plot plots the sample of size $n$ against the (slightly shifted)
$n$-quantiles of the (standard) Normal distribution.

<<pev_qq, cache=FALSE>>=
load("data/F4_crossover.Rdata") # x (salbutamol), y (formoterol)
par(mar=c(4,4,4,4))
qqnorm(y-x)
qqline(y-x, col="grey70")
@
}
\frame{ % -------------------------------------------------------------------->
These visual test require some training.

There are also formal tests of normality (e.g. Shapiro-Wilks)

The S100$\beta$ measurements from the subarachnoidal bleeding example
is certainly not normally distributed.
<<sub_norm>>=
load("data/F10B_subarach.Rdata")
t <- dd$s100b
layout(matrix(1:2, ncol=2))
plot(ecdf(t), do.points=FALSE, verticals=TRUE, xlab="micrgrams / litre", ylab="", main="ECDF")
curve(pnorm(x, mean(t), sd(t)), from=-1, to=2, add=TRUE, lty=2, col="grey60")
qqnorm(t, ylim=c(-0.2, 1.2))
qqline(t)
@
}
\frame{ %  ------------------------------------------------------------------->
\frametitle{A reminder ahead of time}
\begin{center}
\fbox{\textbf{It is very rarely the actual data that is tested for normality!}}
\end{center}
Most of the time the models that assume normality does so for the ''error''
terms, i.e.\ there is a model, depending on the covariates $x$, for the outcome
$Y$ such that
\[ Y = \mbox{some deterministic function of x} + \mbox{noise}. \]

E.g.\ a 2-sample $t$-test assumes that an outcome is normally distributed around a
group-specific mean. Data for such a test might look like this

\begin{center}\begin{tabular}{|c|rrrrrr} \hline
 outcome ($Y$) & 5.1 & 6.2 & 7.9 & 9.2 & 4.7 & $\ldots$ \\
 group ($x$)   &   A &   A &   B &   B &   A & $\ldots$ \\ \hline
\end{tabular}\end{center}

We cannot test the entire $Y$ data for normality. This is evident if imagine the
group effect to be very large\ldots
}
\frame{ %  ------------------------------------------------------------------->
<<fig.height = 2.7>>=
n <- 250
a_mean <- 6
b_mean <- 10
set.seed(12345678)
df <- data.frame(
    x = rep(LETTERS[1:2], each = n),
    Y = rnorm(2*n, rep(c(a_mean,b_mean), each = n), 1)
)
df$resid = df$Y - ifelse(df$x=="A", a_mean, b_mean)
ggplot(df, aes(Y, group = x)) +
    geom_histogram(aes(y = ..density..), binwidth = 0.75) +
    stat_function(fun = dnorm, size = 1, lty = 2,
                  args = list(mean = a_mean)) +
    stat_function(fun = dnorm, size = 1, lty = 2,
                  args = list(mean = b_mean)) +
    labs(x = "Outcome (Y)", y = "Density") +
    theme_bw()
@

It is the deviations (noise/error term) around each group-specific mean that
is supposed to be normal, an estimation of which is called \emph{residuals}.
Subtract the (estimated) group effect from each datapoint to get:

<<fig.height = 2.7>>=
ggplot(df, aes(resid)) +
    geom_histogram(aes(y=..density..), binwidth = 0.5) +
    labs(x = "Residual", y = "Density") +
    stat_function(fun = dnorm, size = 1, lty = 2) +
    theme_bw()
@

}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{Second Summary}
95\% of observations from a Normal population lies within
1.96 multiples of the (population) s.d.  from the (population)
mean.

\rymd Means and in particular s.d. must be distinguished on three levels
\begin{itemize}
\item population,
\item sample, and
\item estimate.
\end{itemize}

\rymd The s.d. of the latter is called the Standard Error\\
(Standard Error of the Mean if the mean is used as estimate.)

\rymd (The sample s.d. is an estimate of the population s.d.)

\rymd The CLT explains why many estimates ('statistics') are
(approx.) Normally distributed even though the population
may not be.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{References}
\begin{itemize}
\item Chapters 1-8, 10: Petrie \& Sabin. \emph{Medical Statistics at a Glance}, Wiley-Blackwell (2009).
\item Puhan et al. \emph{More medical journals should inform their contributors about three
key principles of graph construction}, Journal of Clinical Epidemiology,
\textbf{59} (2006) 1017-1022.
\item Franzblau \& Chung. \emph{Graphs, Tables, and Figures in Scientific Publications: The
Good, the Bad, and How Not to Be the Latter}, American Society for Surgery of the Hand,
\textbf{37A} (2012) 591-596.
\item Kelleher \& Wagener. \emph{Ten guidelines for effective data visualization in scientific
publications}, Environmental Modelling \& Software \textbf{26} (2011) 822-827.
\item L.\ Wilkinson, \emph{The Grammar of Graphics}, 2$^{\mbox{nd}}$ ed., Springer 2005.
%\item H. Wickham, \emph{ggplot2}, 2$^{\mbox{nd}}$ ed. TO APPEAR
\end{itemize}
}
\end{document} % <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
