<<<PRES_OR_HANDOUTS, cache=FALSE, echo=FALSE, include=TRUE, results='asis'>>=
if(!exists("HANDOUT")) HANDOUT <- FALSE
if(HANDOUT){
   cat("
\\documentclass[handout]{beamer}
\\usepackage{pgf,pgfpages}
\\pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=0.5in]
")
} else {
   cat("\\documentclass{beamer}")
}
rm(HANDOUT)
@
\usepackage{beamerthemeclassic}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\hypersetup{colorlinks = true, linkcolor = blue}

<<functions, cache=FALSE, include=FALSE>>=
revsort <- function(sort_x, x_order){
   n <- length(sort_x)
   xx <- rep(NA_real_,n)
   for(k in 1:n){
      xx[x_order[k]] <- sort_x[k]
   }
   xx
}
dotplot <- function(x, skal=100, off=0.1, maxi=1, yfix=1, new=FALSE, ...){
   perm <- order(x)
   xx   <- x[perm]
   n    <- length(xx)
   r    <- diff(range(xx))/skal
   nb   <- rep(0,n)
   y    <- rep(NA_real_,n); y[1] <- yfix
   for(k in 2:n){
      x0 <- xx[-k]
      nb[k] <- length(x0[x0>=xx[k]-r & x0<=xx[k]])
      d <- min(off*nb[k],maxi)
      y[k] <- yfix+runif(1, min=-d, max=+d)
   }
   if(new)
      plot(x=revsort(xx,perm), y=revsort(y,perm), yaxt='n', ylab="", ylim=c(0,2), ...)
   else
      points(x=x, y=revsort(y,perm), ...)
}
.yellow <- wes_palette("Cavalcanti1", 5)[1]
.green <- wes_palette("Cavalcanti1", 5)[2]
.grey <- wes_palette("Cavalcanti1", 5)[3]
.blue <- wes_palette("Cavalcanti1", 5)[4]
.red <- wes_palette("Cavalcanti1", 5)[5]
@

\newcommand{\pr}{\mathbf{Prob}}
\newcommand{\el}{\mbox{\;or\;}}
\newcommand{\rymd}{\vspace{0.3cm}}
\newcommand{\rymda}{\vspace{0.5cm}}
\newcommand{\code}{\texttt}
%\setbeamersize{text margin left=6mm, text margin right=2mm}  % DEFAULT
\setbeamersize{text margin left=3mm, text margin right=2mm}

\title{Introduction to Biostatistics \\ Lecture 1B and 2}
\author{Henrik Renlund}
\date{Fall 2020}

\begin{document} % >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
\frame{ % -------------------------------------------------------------------->
\frametitle{Introduction to Biostatistics}
\begin{center}
\begin{figure}
\includegraphics[scale=0.39]{pics/livinghistogram.jpg}
\end{figure}
\end{center}
\begin{flushright}
{\tiny Arranged by Linda Strausbaugh (Genetics 147:5, 1997)}
\end{flushright}
}
\frame{ % -------------------------------------------------------------------->
\titlepage
\begin{center}
\includegraphics[scale=0.2]{pics/ucrlogo.pdf}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Contents of Lecture 1-2}
\tableofcontents
}
\frame{ % -------------------------------------------------------------------->
\frametitle{What shall we learn today?}
\begin{itemize}
   \item Data description
      \begin{itemize}
         \item Graphs
         \item Tables and summary measures
      \end{itemize}
   \item Probability Models
      \begin{itemize}
         \item Glimpse at theory (models/distributions)
         \item The Normal distribution
         \item Some properties of samples and the Central Limit Theorem.
      \end{itemize}
\end{itemize}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Descriptions]{Data and descriptive statistics} %%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
  \frametitle{Types of data}

  A data set contains one or more \emph{variables} for each unit of study
\begin{center}\begin{tabular}{ccccccc}
\code{ID} & \code{Sex} & Age & \code{Children} & \code{Albumin} & \code{Diabetes} & \code{Happiness} \\
1 & M & 67 & 0 & 3.92 & 0 & {\LARGE $\smile$ } \\
2 & F & 71 & 3 & 4.12 & 0 & {\LARGE $\frown$ } \\
3 & F & 49 & 1 & 4.75 & 1 & {\LARGE $-\phantom{.}$} \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$
\end{tabular}\end{center}
Data categories:
\begin{itemize}
   \item Categorical
      \begin{itemize}
         \item nominal, e.g.\ \code{Sex}, \code{Diabetes}, \emph{or}
         \item ordinal, e.g.\ \code{Happiness}: $\frown, -, \smile$.
      \end{itemize}
   \item Numerical
      \begin{itemize}
         \item discrete; typically integer valued 0, 1, 2, \ldots, like \code{Children}, \emph{or}
         \item continuous; i.e.\ any value in an interval, like \code{Albumin}.
      \end{itemize}
\end{itemize}
The category determines what analyses are available.

}
\frame{ % -------------------------------------------------------------------->
\frametitle{Data management}
Make sure you and your software agree on variable formats.

\rymd
This is especially important if data has been transferred, e.g.\ between formats
or operating systems.

\rymd
Common problems:
\begin{itemize}
   \item date- and categorical data stored as integers
   \item numerical values stored as text (due to ',' vs. '.')
   \item how are missing values represented? "Unknown"?
\end{itemize}

}
\frame{ %-------------------------------------------------------------------->
\frametitle{What about missing data?}

\textbf{'Good' scenario:} Suppose in an experiment a batch of samples are
destroyed throught some random accident. Typically this only leads to a smaller
sample size, but there is no problem running the analysis as planned.

\rymd \textbf{'Bad' scenario:} Suppose we study severity of myocardial
infarctions with a model that includes sex, age, BMI (some missing) and
smoking status (some missing). Worry: the reason for missing depends on the
value.

\rymd The statistical software default is to include only those individuals with
complete case data on all variables in the analysis.

\rymd This \textbf{complete case analysis} will only give an unbiased
result if the reason that a variable is missing has nothing to do with the
actual value (and/or the outcome).
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Solutions\ldots ish}
There is no trick that guarantees a non-biased analysis.

\rymd \textbf{Single imputation} e.g.\ replace missing value with a "typical"
value for that variable (e.g. mean or median). This method underestimates the
variance in the variable and will give overly optimistic results.

\rymd \textbf{Multiple imputation} create multiple imputed data sets where the
missing values are replaced differently in each iteration (perhaps even
"predicted" from other covariates).

\rymd
\begin{quote}
"It is not that multiple imputation is so good; it is really that other methods
  for adressing missing data are so bad."
\begin{flushright}
(Donald Rubin)
\end{flushright}
\end{quote}
\textbf{N.B.} we typically do not impute our outcome data.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualization of (continuous) data}
A sufficiently small data set might not need visualization.

\rymda
The level (g/dL) of the protein albumin was recorded in a
sample (of size 8) of mice (56 days old):
<<show_albumin, results='asis'>>=
load("data/F3_albumin.Rdata")
out <- paste(alb, collapse="\\quad")
cat("\\[", out, "\\]")
@

\rymda One simple way to get some handle on data is to order it:
<<show_albumin_sorted, results='asis'>>=
load("data/F3_albumin.Rdata")
out <- paste(sort(alb), collapse="\\quad")
cat("\\[", out, "\\]")
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Dotplot of albumin data}
A dotplot is a one dimensional plot of the data.

\rymd
<<plot_alb, fig.align='center', fig.height=3, fig.width=11>>=
load("data/F3_albumin.Rdata")
par(mar=c(4,1,1,1))
plot(
   x = alb, y = rep(2,8),
   yaxt='n', ylab="",
   ylim=c(0.8,1.2),
   xlim=c(1.7,2.2),
   bty = 'n',
   xlab="g / dL",
   cex.lab=1.2,
   main=""
)
points(sort(alb), rep(1,8))
## wtf <- axis(2, at=1, labels=FALSE)
## text(
##    x=1.75, y=wtf,
##    labels=c("dots"),
##    cex=1.2,
##    xpd=TRUE,
##    pos=2,
##    offset=0
## )
par(.par_reset)
@

If there are non-unique (or close) points, the data set may appear smaller than
it really is.

\rymd This can be alleviated by
\begin{itemize}
   \item perturbation, or,
   \item (alpha) transparency.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Subarachnoidal bleeding}
A biomarker - the protein S100$\beta$ - was measured for 113 individuals with
aneurysmal subarachnoid hemorrhage.

\rymd
<<plot_subarach, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,7,0,0))
plot(
   x=dd$s100b, y=rep(3,113),bty = 'l',
   ylab="", yaxt='n', ylim=c(0.5,3.2),
   xlab="microgram / litre",
   cex.lab=1.2
)
points(x=dd$s100b, y=rep(2,113), pch = 16, col = rgb(0,0,0,1/4))
dotplot(x = dd$s100b, maxi = 0.5)
wtf <- axis(2, at=1:3, labels=FALSE)
text(
   x=0, y=wtf,
   labels=c("Perturbation", "Transparency", "Overlapping"),
   cex=1.2,
   xpd=TRUE,
   pos=2,
   offset=1
)
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Dotplot and groups}
Dotplots can display groups.

\rymd
<<sub_comp, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
x <- dd$s100b[dd$outcome=="Poor"]
y <- dd$s100b[dd$outcome=="Good"]
good_col <- .yellow
bad_col  <- .green
par(mar=c(4,5,0,0))
layout(matrix(1:2,nrow=2))
dotplot( x=dd$s100b, new=TRUE, col=ifelse(dd$outcome=="Good", good_col, bad_col),
         xlab="", maxi=0.6, skal=75, bty = 'n')
legend(x = -0.14, y = 1.5, c("Good", "Poor"), col=c(good_col, bad_col), cex=1.2,
       lty=NULL, pch=1, title="Outcome", bty='n', xpd = TRUE)
plot(x=dd$s100b,rep(1,113),type='n',xlab="microgram / litre",ylab="",
     yaxt='n', ylim=c(0.5,2.5), cex.lab=1.2, bty = 'l')
dotplot(x, col=bad_col, maxi=0.5)
dotplot(y, col=good_col, maxi=0.5, yfix=2)
wtf <- axis(2,at=1:2, labels=FALSE)
text(x=0, y=wtf, labels=c("Poor", "Good"), cex=1.2,
     xpd=TRUE, pos=2, offset=1)
layout(matrix(1,nrow=1))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{"Table 1"}
It is useful to provide a summary table of the variables you are working with.
Choice of descriptive measures may be context dependent.
\begin{table}\begin{center}
%%\caption{Data set on 84 individuals.}
\begin{tabular}{|l|cc|cc|} \hline
\emph{variable} &  \multicolumn{2}{c|}{\texttt{\underline{Diabetes: No}}} & \multicolumn{2}{c|}{\texttt{\underline{Diabetes: Yes}}}\\
\multicolumn{1}{|r|}{\emph{value}} &  \emph{mean} & \emph{sd}  & \emph{mean} & \emph{sd} \\  \hline %\cline{3-4}
\code{Age}   & 32.0 & 15.9 & 32.5 & 14.1\\
\code{Albumin}  & 4.20 & 0.37 & 3.80 & 0.50\\ \cline{2-5}
   & \emph{percent} & \emph{n} & \emph{percent} & \emph{n} \\ \cline{2-5}
\code{Sex} &&&& \\
\multicolumn{1}{|r|}{M}  & 64\% & 27 & 52\% & 22 \\
 \multicolumn{1}{|r|}{F} & 36\% & 15 & 48\% & 20 \\
\code{Happiness} &&&& \\
\multicolumn{1}{|r|}{$\frown$}   & 61\% & 19 & 36\% & 15 \\
\multicolumn{1}{|r|}{$-$}        & 23\% & 7  & 36\% & 15 \\
\multicolumn{1}{|r|}{$\smile$}   & 16\% & 5  & 28\% & 12 \\ \hline
\end{tabular}
\end{center}\end{table}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Percentiles (Measure of location)}
\begin{itemize}
\item The $k$th percentile is a value $v$ such that $k$ percent of your data lies below (or at) $v$. (Usually not uniquely defined.)

  \rymd \item The 50th percentile (the \emph{median}) is the point which divides your ordered sample equally. (Only 'unique' if sample is odd, else use mean of the two midpoints.)

   \rymd \item \emph{The Quartiles:} Q1 is the 25th percentile, Q2 is the 50th percentile and Q3 is the 75th percentile.

   \rymd \item We can describe all percentiles with the \emph{cumulative
     frequency graph} (CF) also called the \emph{emprical cumulative
     distribution function} (ECDF)
\end{itemize}
}
\frame{ %-------------------------------------------------------------------->
\frametitle{Creating a CF}

A CF shows the cumulative frequency (or cumulative proportion) and thus starts
at 0 for points smaller than the smallest point of the data set. Then it is a
step-wise function with jumps according to:

  \begin{center}\begin{tabular}{|r|r|r|r|} \hline
      Unique points & Count & Cumulative count & Cumulative proportion \\ \hline
      0.03 & 1 & 1 & $\frac{1}{113} \approx 0.009$ \\
      0.04 & 5 & 6 & $\frac{6}{113} \approx 0.053$ \\
      0.05 & 3 & 9 & $\frac{9}{113} \approx 0.080$ \\
      $\vdots\phantom{00}$ & $\vdots$ & $\vdots$ & $\vdots\phantom{000}$ \\
      1.15 & 1 & 113 & 1.000 \\ \hline
  \end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Cumulative frequency for S100$\beta$}
$\phantom X$
<<subarach_ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,4,0,0))
plot.ecdf(ecdf(dd$s100b),  verticals=TRUE, do.points=FALSE, ylab="",
          xlab="microgram / litre", main="", ylim=c(-0.08,1), cex.lab=1.2)
points(dd$s100b, rep(-0.05,113), pch =16, col = rgb(0,0,0,alpha = 1/4))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Cumulative frequency function}

CF's can also display group differences.

<<subarach_2ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,4,0,0))
plot.ecdf(ecdf(dd$s100b[dd$outcome=="Good"]),  verticals=TRUE, do.points=FALSE,
          xlim=c(0,1.2), main="", xlab="microgram / litre", ylab="", cex.lab=1.2)
plot.ecdf(ecdf(dd$s100b[dd$outcome=="Poor"]),  verticals=TRUE, do.points=FALSE,
          lty=2,add=TRUE)
legend(x=0.9,y=0.4, c("Good", "Poor"), title="Outcome", lty=c(1,2), bty='n', cex=1.2)
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
  \frametitle{Survival curves}
A survival curve is a CF. Survival (time-to-event) data is typically \emph{right censored} and the
curve thus needs to be estimated (Kaplan-Meier) - more on that later in the course.

<<"colon-ex", include = TRUE, fig.cap = cap, fig.height = 4>>=
## table("s"=colon$status, "e"= colon$etype)
## nrow(colon) ## 1858
## length(unique(colon$id)) ## 929
## etype == 2 is death, == 1 is recurrence
X <- subset(colon, etype == 2, select = c("id", "rx", "status", "time"))
s <- broom::tidy(survfit(Surv(time, status) ~ rx, data = X))
s$Treatment <- ifelse(s$strata == "rx=Obs", "Observation",
                  ifelse(s$strata == "rx=Lev+5FU", "Lev + 5FU", "Lev"))
## table(s$strata, s$group, useNA="a")
ggplot(s, aes(time, estimate, color = Treatment)) +
    geom_line() +
    scale_y_continuous(limits = c(0,1)) +
    scale_x_continuous(limits = c(0, 3000), expand = c(0,0)) +
    theme(legend.position = "bottom") +
    labs(x="Days until death or censoring", y = "Survival")
cap <- paste0("Survival curves for 3 different treatments of colon cancer; ",
              "observation only, Levasimole, or Levasimole and 5-FU. ",
              "(Moertel 1991)")
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Average value (Measure of location)}
An average value should be representative of the entire data set.

\begin{itemize}
\item  \textbf{The median:} is the midpoint of the ordered numerical sample
  when one iteratively cancelles the smallest and largest points.
\item  \textbf{The mean:} is the center of gravity of a data set. \\
Note: unlike the median, it is sensitive to extreme values.
%% \item  \textbf{The mode:} is the single most common value of a data point. \\
%% (Mostly meaningful for categorical data.)
\end{itemize}
<<"company-viz", include = TRUE, fig.height = 4>>=
x <- c(19,21,22,24,27,55)
z <- c(19,21,22,24,27)
par(mar=c(2,1,1,1))
plot(c(z,x), rep(2:1,c(5,6)),
     bty = 'n', yaxt = 'n',
     ylab = '', xlab = 'Income',
     pch = 15, col = rep(c("black", "red"), c(10,1)),
     ylim = c(0.5,2.5))
a <- 0.7
b <- 0.97
d <- 0.05
l <- 0.975
v = 15
lines(x = c(0,100), y = c(l,l), col = "gray")
arrows(x0 = mean(x), y0 = a, y1 = b, angle = v)
text(x = mean(x), y = a-d, labels = "Mean")
arrows(x0 = median(x), y0 = 2-a, y1 = 2-b, angle = v)
text(x = median(x), y = 2-a+d, labels = "Median")
text(x = 40, y = 2-a+2*d, cex = 1.2,
     labels = "Same data set plus an extreme value:")
arrows(x0 = 45, x1 = max(x)-1, y0 = 2-a, y1 = 2-b, angle = v)
lines(x = c(0,100), y = c(1+l,1+l), col = "gray")
arrows(x0 = mean(z), y0 = 1+a, y1 = 1+b, angle = v)
text(x = mean(z), y = 1+a-d, labels = "Mean")
arrows(x0 = median(z), y0 = 3-a, y1 = 3-b, angle = v)
text(x = median(z), y = 3-a+d, labels = "Median")
text(x = 40, y = 3-a+2*d, cex = 1.2,
     labels = "A data set without extreme values:")
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Mean or median?}
Ex: A small company has 5 employees, who earns 19, 21, 22, 24, 27 (K SEK)
and a boss who earns 55. (The numbers from the previous plot.)
\begin{center}
\begin{tabular}{|l|cc|} \hline
Salaries & Excluding boss    & Including boss \\ \hline
Median   & $22\phantom{.0}$  & 23 \\
Mean     & 22.6              & 28 \\ \hline
\end{tabular}
\end{center}

Ex: The number of hospitalization days per individual in Uppsala is likely to be
very skewed. The median might be of most interest on an individual level, wheras
the mean (which is essentially the sum) is of more interest to whoever is in
charge of the hospital budget (as well as other things).

\rymd
In fact: the median is probably 0! One could e.g.\ describe this distribution by
the median among those with non-zero hospitalization days.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Measuring of spread}

\begin{itemize}
   \item  \textbf{Range} The difference between the maximum and the minimum value.

   \item  \textbf{Interquartile range (IQR)}: Q3-Q1.

   \item \textbf{Standard deviation (sd)} is given by the formula,
   \[ s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar x)^2}. \]
   %It is a measure of spread with expressed in the same unit as the data.
   Where $x_1, x_2, \ldots, x_n$ is the sample  and
   $ \bar x=\frac 1n\sum_{i=1}^n x_i$ is the (sample) mean.

   It is (\emph{approximately only}) the mean distance to the mean value.

   \rymd \textbf{Note}: the sd in the previous salary example is 3.0 and 13.5 if
   the boss is excluded or included, respectively.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Boxplot of S100$\beta$}
The boxplot usually show min, Q1, med, Q3 and max (the "5-point summary")\ldots
<<sub_box_1, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,1,0,0))
dotplot(dd$s100b, new=TRUE, col="grey60", xlab="microgram / litre", cex.lab=1.2)
boxplot(dd$s100b, horizontal=TRUE, boxwex=2, range=0, add=TRUE, col = rgb(0,0,0,alpha=0))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Boxplot}
\ldots but most software mark points that are more than
1.5 times the IQR away from 'the box'.
<<sub_box_2, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,1,0,0))
boxplot(dd$s100b, horizontal=TRUE, boxwex=1, col = rgb(0,0,0,alpha=0),
        xlab="microgram / litre", cex.lab=1.2)
#axis(2, at=seq(0,2,0.1))
qs <- quantile(dd$s100b)
t_s <- 1.2
arrows(x0=qs[2], x1=qs[4], y0=0.7,y1=0.7, code=3)
text(x=(qs[2]+qs[4])/2, y=0.7, pos=1, "IQR", cex=t_s )
p0 <- 2.5*qs[4]-1.5*qs[2]
arrows(x0=qs[4], x1=p0, y0=.8, y1=.8,code=3)
abline(v=p0, lty=2, col="grey60")
text(x=(qs[4]+p0)/2, y=0.8, pos=1, "1.5*IQR", cex=t_s)
text(x=(p0+max(dd$s100b))/2, y=0.75,pos=1, "'Outliers'", cex=t_s)
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Connection between boxplot and cumulative frequency}
The boxplot contains less information.
<<sub_box_ecdf, fig.align='center', fig.height=5, fig.width=11>>=
load("data/F10B_subarach.Rdata")
par(mar=c(4,3,0,0))
plot.ecdf(ecdf(dd$s100b),  verticals=TRUE, do.points=FALSE, ylab="",
          xlab="microgram / litre", main="", yaxt='n', cex.lab=1.2)
axis(2, at=seq(0,1,0.25))
abline(h=c(0.75,0.25), lty=2, col="grey60")
boxplot(dd$s100b, add=TRUE, horizontal=TRUE, at=0.5, boxwex=1, lwd=2, col = rgb(0,0,0,alpha=0))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Pattern or detail?}
Here is fake data whith 7 subgroups (a-g).

<<multiple-ecdf-vs-boxplots, include = TRUE, fig.heigth = 8>>=
m <- 7; n <- 50
set.seed(19791224)
x <- factor(rep(letters[1:m], each = n))
s <- rep(runif(m), each = n)
y <- rnorm(n * m, as.numeric(x) + 5, 3 * (s + .1))
layout(matrix(1:2, nrow = 2))
par(mar=c(1,5,0,0))
boxplot(y ~x, horizontal = TRUE, ylim = c(3, 20), xaxt = 'n', ylab = "Groups")
te <- tapply(y, x, ecdf)
par(mar=c(2,5,0,0))
plot(te[[1]], main = "", verticals = TRUE, do.points = FALSE, xlim = c(3, 20), xlab = "", ylab = "CF:s")
for(k in 2:m) plot(te[[k]], verticals = TRUE, do.points = FALSE, add = TRUE, lty = k)
layout(matrix(1, nrow = 1))
par(.par_reset)
@
}
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Advanced graphics\ldots}
%% Anyone seriously interested in graphics might want to look at Wilkinson's \emph{The Grammar of Graphics}, which provides a framework for thinking about data visualization. These ideas are implemented in the R package \textbf{ggplot2} - which provides tools for mapping variables to aestic properties, adding layers of statistical computations, faceting, etc.

%% <<ggplot2-promotion, include = TRUE>>=
%% mtcars$am <- as.logical(mtcars$am)
%% mtcars$vs <- factor(mtcars$vs, labels = c("V engine", "Straight engine"))
%% ggplot(mtcars, aes(disp, mpg)) +
%%    geom_point(aes(shape =  factor(am), color = factor(gear), size = qsec)) +
%%    geom_smooth(method = "lm", color = "black") +
%%    facet_wrap(~vs, nrow = 2, scales = "free_y") +
%%    scale_color_manual(values = wes_palette("Cavalcanti1", 5)[c(1,2,5)], name = "Gears") +
%%    scale_size(range = c(3,12), name = "Mile time") +
%%    scale_shape_discrete(name = "Manual") +
%%    labs(x = "Miles per Gallon", y = "Displacement") +
%%    theme_bw()
%% @
%% }
\frame{ % -------------------------------------------------------------------->
\frametitle{Some rules of thumb for tables and graphs}
Both:
\begin{itemize}
\item Table/graph + caption should be self-contained.
\end{itemize}
Tables:
\begin{itemize}
\item Captions \emph{above} the table.
\item Avoid excessive precision and use adequate measures of location and spread.
\end{itemize}
Graphs:
\begin{itemize}
\item Captions \emph{below} the graph
\item 'Economy' Do not make a graph which is more easily expressed in text or a
  small table, e.g. graph with a single boxplot.
\item Avoid 2D graphs shown in 3D.
\item Colors are tricky (colorblindness, black/white-printing, etc.) - a website
  like \href{https://colorbrewer2.org}{Colorbrewer (https://colorbrewer2.org)}
  might guide color choice.
\end{itemize}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Models]{Probability theory and models} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{ % -------------------------------------------------------------------->
\frametitle{Probability theory and models}
Note: this is not a theoretical course in any mathematical sense.

\rymd Most lectures will be guided by applications.

\rymd However, a view towards theory and some fundamental (mathematical) results can
give a better understanding of some of the methods employed in this course.

\rymd So here goes\ldots
}
\frame{ % -------------------------------------------------------------------->
Probability theory studies models of random data. A \textbf{model} is a way of specifying the range of possible values and the probability with which these occur.
\begin{itemize}
   \item \textbf{Probability functions} describe discrete numeric/categorical data
   \item \textbf{Density functions} describe continuous (numeric) data
\end{itemize}

\rymd
\textbf{Probability theory:} given model (model parameters, or other aspects) - describe how data behave. E.g.\
   \begin{itemize}
      \item specific results: how likely are specific deviations
      \item general results: Law of Large Numbers, Central Limit Theorem, etc.
   \end{itemize}

\rymd
\textbf{Inference theory:}  given data, what is a likely model/parameters or other aspects of the underlying distribution (without specifying model = non-parametric statistics).
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Probability models for categorical or integer-valued data}
A yet undetermined random value is called a \emph{random variable} (RV).

\rymd Let $Z=$'the outcome of the throw of a die'.
Then $\pr(Z=k)=1/6$ for all $k=1,2,\ldots,6$, or, equivalently

\begin{center}\begin{tabular}{|c|cccccc|} \hline
Value $k$ & 1  & 2 & 3 & 4 & 5 & 6 \\
$\pr(Z=k)$ & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6\\ \hline
\end{tabular}\end{center}

\rymd Suppose that in the population there are 49 \% non-smokers, 20 \% former smokers
and 31\% current smokers. Then the smoking status $X$ of a person selected
at random is a RV with a probability function

\rymd
\begin{center}\begin{tabular}{|c|ccc|} \hline
Value $v$  & non  & former & current \\
$\pr(X=v)$ & 0.49 & 0.20   & 0.31 \\ \hline
\end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->
Five samples from three different sampling sizes from previous distribution
<<fig.height = 7>>=
set.seed(20101212)
pf <- c(0.49,0.20,0.31)
m <- 5
values <- c("non", "former", "current")

foo_bar <- function(n, l = FALSE){
   # n <- 30
   s <- factor(sample(values, size = m*n, replace = TRUE,
                      prob = pf), levels = values)
   g <- rep(sprintf("%d",1:m), each = n)
#    barplot(pf, width = m, border = "black", col = "black",
#            density = 9, ylim = c(0,0.7), lwd = 2, angle = +45, main = paste0("Sample size ", n))
   barplot(prop.table(table(g, s),1), col = wesanderson::wes_palette("Cavalcanti1", 5),
           beside = TRUE, legend = l,  ylim = c(0,0.7), main = paste0("Sample size ", n),
           args.legend = list(x="topright", title = "Sample", horiz = TRUE))
   barplot(pf, width = m, border = "black", col = "black",
           density = 15, lwd = 2, angle = +45, add = TRUE)
}

par(mar=c(4,5,2,1))
layout(matrix(1:4, nrow = 2, byrow = TRUE))
barplot(pf, width = m, names.arg = values, border = "black", col = "black", ylim = c(0,0.7),
        main = "True distribution", density = 15, lwd = 2, angle = +45) ## legend = l2,
foo_bar(25)
foo_bar(100)
foo_bar(1000, l = TRUE)
layout(matrix(1, nrow = 1))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{FEV data set}
430 children (9-17 years of age) had their age, forced expiratory volume
in 1 second (FEV) and smoking status recorded.

\rymd A barchart is a way to visualize a variable with a small number
of unique values (often categorical). They are visual analogous
of tables.

\rymd Ex: how do the ages distribute over smoking status?
<<tab_smoker, results='asis'>>=
load("data/F8_smoking.Rdata") # dd
with(dd, tabsmok <<- table( age=age, smoker=smoker))
latex(
   object = t(tabsmok),
   file = "",
   title = "Smoking",
   cgroup = "Age"
)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualizing 'age' versus 'smoking'}
<<smoker>>=
load("data/F8_smoking.Rdata")
par(mar=c(4,4,0,0))
barplot(tabsmok, beside=TRUE, legend=TRUE, ylab="Frequency", col=brewer.pal(9, "YlGn"))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
%\frametitle{}
If the groups (smokers/non-smokers) aren't balanced
it is difficult to compare the distributions.

Tabulate/plot the percentages within groups:
<<tab_smoker2, results='asis'>>=
load("data/F8_smoking.Rdata") # dd
with(dd, tabsmok2 <<- addmargins(prop.table(table( age=age, smoker=smoker), 2), 1))
latex(
   tabsmok2,
   digits=2,
   file="",
   title="Age",
   cgroup="Smoking (proportion)"
)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Percentages within smoking groups}
The distributions are now easier to compare.
<<plot_smoker2>>=
load("data/F8_smoking.Rdata")
with(dd, tabsmok3 <<- 100*prop.table(table( age=age, smoker=smoker), 2))
par(mar=c(4,4,1,0))
barplot(tabsmok3, beside=TRUE, legend=TRUE, ylab="Percent", col=brewer.pal(9, "YlGn"))
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Flipping the axis}
The "right" visualization might not be obvious. A binary categorical variable
can be suitable to \emph{stack} in a bar chart:

<<plot_smoker3>>=
load("data/F8_smoking.Rdata")
dd$age <- factor(dd$age)
ggplot(dd, aes(age, fill=smoker)) +
   geom_bar(position="fill") +
   labs(x="Age", y="Percentage within year of age") +
   scale_fill_manual(values=c(.blue, .red), name="Smoker") +
   theme_classic()  +
   scale_y_continuous(breaks = seq(0, 1, by = 0.25), labels = sprintf("%s%%",seq(0,100,by=25)))
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Probability model for continuous data}
%%Recall that a RV is a yet undetermined value among several possible numbers.

A continuous random variable is described by its \emph{density function}.

\includegraphics[scale=0.31]{pics/density_function.png}

If $X$ has density function $f$ as above, then we compute probabilities as
\[ \pr( a\leq X \leq b)=\;\mbox{Area(a,b)}. \]
}
\frame{ % -------------------------------------------------------------------->
  \frametitle{Example: The Uniform distribution}
A computer generated random number typically tries to mimic the \emph{uniform
  distribution} (on the $[0,1]$ interval).
<<"uniform", include = TRUE>>=
par(mar = c(2,4,1,1))
curve(dunif(x, 0, 1), from = 0, to = 1, xlim = c(-0.2, 1.2), ylim = c(0,1),
      ylab = "Density", xlab = "", bty = "l")
zero <- function(x) rep(0, length(x))
curve(zero(x), from = -1, to = 0, add = TRUE)
curve(zero(x), from = 1, to = 2, add = TRUE)
par(.par_reset)
@
Any number (or interval) within $[0,1]$ is as likely as any other (of the same length).
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Making a histogram}
  A histogram is a categorization of the x-axis into "bins", typically as
  intervals of the same range, and a statistic associated with each.

  \rymd
  The FEV dataset has 430 (numercial) FEV-measurements between 1 and 6.

  \rymd Data underlying a histogram:
  \begin{center}
  \begin{tabular}{|c|r|r|r|} \hline
    Interval & Count & Proportion & Density  \\ \hline
  $(1.0, 1.5]$ &  1 & $\frac{1}{430} \approx 0.0023$ & $\frac{1/430}{1.5-1.0}\approx 0.0047$ \\
  $(1.5, 2.0]$ & 27 & $0.063\phantom{0}$ & $0.13\phantom{00}$ \\
  $(2.0, 2.5]$ & 89 & $0.21\phantom{00}$ & $0.41\phantom{00}$ \\
  $\vdots$ & $\vdots$ & $\vdots\phantom{0000}$ & $\vdots\phantom{0000}$ \\
  $(5.5, 6.0]$ & 3 & 0.0070 & $0.014\phantom{0}$ \\ \hline
  \end{tabular}
  \end{center}
}
\frame{ % -------------------------------------------------------------------->
The shape of a histogram estimates the shape of the density function.
<<test-hist, fig.height = 4>>=
load("data/F8_smoking.Rdata")
# h <- hist(dd$fev, plot = FALSE)
par(mar=c(4,5,2,1))
z <- 1.5
u <- z
layout(matrix(1:3, nrow = 1))
hist(dd$fev, main = "", xlab = "FEV (L)", ylab = "Count", col=.blue, cex.axis = z, cex.lab = u)
hist(dd$fev, freq = FALSE, main = "", xlab = "FEV (L)", yaxt = 'n', ylab = "Percent", col=.blue, cex.axis = z, cex.lab = u)
vid <- seq(0,0.5,0.1)
axis(2, at = vid, labels = sprintf("%s", .5*100*vid), cex.axis = z)
hist(dd$fev, freq = FALSE, main = "", xlab = "FEV (L)", col=.blue, cex.axis = z, cex.lab = u)
# b <- c(1,2,2.5,3,3.5,4,6)
# h2 <- hist(dd$fev, plot = FALSE, breaks = b)
# h2_mod <- h2
# h2_mod$density <- h2$density * diff(h2$breaks)
# plot(h2_mod, main = "", xlab = "FEV (L)", col=.blue, ylab = "Percent")
# hist(dd$fev, breaks = b, main = "", xlab = "FEV (L)", col=.blue)
layout(matrix(1,nrow = 1))
par(.par_reset)
@
"Density" is more abstract but
\begin{itemize}
   \item gives right scale for density function estimate (easy to correctly plot candidate model on top of histogram)
   \item allows for varying "bins"
   \item allows for comparison between very different sample sizes
\end{itemize}
}
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Summary}
%% \begin{center}
%% \begin{tabular}{|c|c|p{5cm}|} \hline
%% Graph & Summary Measure & Theory \\ \hline \hline
%% CF & percentiles & (Cdf) \\ \hline
%% Boxplot & min, Quartiles, max & \\ \hline
%% Bar charts & & Probability functions (discrete/categorical RV) \\ \hline
%% Histograms & & Density functions (continuous RV)\\ \hline
%% & median, IQR & any distribution\\ \hline
%% & mean, s.d. & symmetrical distribution ($\approx$ Normal distribution) \\ \hline
%% \end{tabular}
%% \end{center}
%% }
\frame{ % -------------------------------------------------------------------->
\frametitle{The Normal Distribution}
Sometimes we assume that the population follows a Normal density curve.

<<fev6>>=
load("data/F8_smoking.Rdata") # dd
n <- 11
par(mar=c(4,4,0,0))
h0 <- hist(dd$fev, plot=FALSE)
curve(dnorm(x,mean(dd$fev), sd(dd$fev)), from=1, to=6, lwd=2,ylim=c(0,1.05*max(h0$density)), ylab = "Density", xlab  = "FEV (L)")
hist(
   dd$fev,
   freq=FALSE,
   ylim=c(0,1.05*max(h0$density)),
   xlab="FEV (L)",
   main="",
   col=.blue, #col="grey80",
   breaks=seq(1,6,length.out=n),
   add = TRUE
)
curve(dnorm(x,mean(dd$fev), sd(dd$fev)), from=1, to=6, lwd=2, add =TRUE, lty = 2)
par(.par_reset)
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{The Normal Distribution}
The Normal, Gauss, or Bell, curve is centered at (the mean) $\mu$ with a standard
devation of $\sigma$, according to the equation:
\[ f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{\frac{-(x-\mu)^2}{2\sigma}}. \]
The special case of $\mu=0$ and $\sigma=1$ is called a \emph{standard normal
  distribution}.

\rymd
\textbf{Digression:} Any sample can be "standardized" by
subtracting the mean and dividing by the standard deviation.

If $x_1, x_2, \ldots, x_n$ is a sample (of size $n$) with mean
$\bar x = \frac1n\sum_1^n x_i$ and
$sd = \sqrt{\frac1{n-1}\sum_1^n(x_i-\bar x)^2}$, then the transformation
\[ \frac{x_1-\bar x}{sd}, \frac{x_2-\bar x}{sd}, \ldots, \frac{x_n-\bar x}{sd}, \]
is \emph{standardized} (it has mean 0 and sd 1).
}
\frame{ % --------------------------------------------------------------------->
\frametitle{Properties of the standard Normal distribution}
The standard Normal distribution is centered at 0 and has a standard deviation of 1.

\rymd
{\centering\fbox{95\% of the 'probability mass' lies within $\pm 1.96$.}\par}
<<normal_stuff, fig.width=9, fig.height=5, include=FALSE>>=
x <- seq(-3.5,3.5,length.out=100)
y <- dnorm(x, 0, 1)
plot( c(-3.2,3.2),c(0,0.4), col="white",
      main="",ylab="Density",xlab="")
v <- qnorm(0.975)
xx <- seq(-v,v,length.out=100); yy <- dnorm(xx,0,1); xx <- c(xx[1],xx,xx[100]); yy <- c(0,yy,0)
polygon( xx,yy,  lty=2, col=.blue) # col="lightblue",
points( c(-v,-v), c(0,0.28), type='l', lty=2)
text( -v, 0.3, label=paste("-",signif(v,3),sep=""), cex=1.5 )
points( c(v,v), c(0,0.28), type='l', lty=2)
text( v, 0.3, label=paste("+",signif(v,3),sep=""), cex=1.5 )
points( x,y, type='l', lwd=2)
text( 0,0.15, "95%",cex=2)
@

<<plot_code_normal_stuff, results='asis', cache = FALSE>>=
plot_code <- sprintf("\\includegraphics[scale=0.47]{figure/%s}\n", paste0("normal_stuff-",1:2))
cat(plot_code, sep="")
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{The Normal distribution N$(\mu,\sigma)$}
is determined by its mean ($\mu$) and standard deviation ($\sigma$).

\rymd
{\centering\fbox{If $X$ is N(0,1) then $\mu+\sigma X$ is N$(\mu,\sigma)$.}\par}
<<normals>>=
n <- 100
x <- seq(-3,8,length.out=n)
y0 <- dnorm(x, 0, 1)
y1 <- dnorm(x, 4, 1)
## y2 <- dnorm(x, 3, 3)
y2 <- dnorm(x, 0, .5)
y3 <- dnorm(x, 4, 2)
m <- max(c(y1,y2,y3))
plot( 0, 0, col="white",ylim=c(0,m),xlim=c(-2,7),xlab="",ylab="Density")
points(x, y0, lty = 1, col = "lightgrey", type = "l", lwd = 3)
myCol <-  c(.blue, .green, .yellow) #brewer.pal(3,"Set2")
for(k in 1:3){
   points( x, get( paste("y",k,sep="") ), type='l', col=myCol[k], lwd=3)
}
text( -1.5, 0.30, "N(0,1)", cex = 2, col = "lightgrey")
text( 5.4, 0.35, "N(4,1)", col=myCol[1], cex=2)
text( 1.2, 0.55, "N(0,0.5)", col=myCol[2], cex=2)
text( 4, 0.25, "N(4,2)", col=myCol[3], cex=2)
@
}
\frame{ % --------------------------------------------------------------------->
\frametitle{Properties of the Normal distribution}
If $X$ is N$(\mu,\sigma)$, then 95\% of observations will
be between

\rymd
{\centering $\mu-1.96\sigma$ and $\mu+1.96\sigma$.\par}
<<plot_N_properties>>=
Mu <- 6
Sd <- 2.5
x <- seq(Mu-3*Sd,Mu+3*Sd,length.out=100)
y <- dnorm(x, Mu, Sd)
plot( c(Mu-2.8*Sd,Mu+2.8*Sd),c(0,0.25), col="white",
      main="",ylab="Density",xlab="")
v <- qnorm(0.975)
xx <- seq(Mu-v*Sd,Mu+v*Sd,length.out=100)
yy <- dnorm(xx,Mu,Sd)
xx <- c(xx[1],xx,xx[100])
yy <- c(0,yy,0)
polygon( xx,yy, col=.blue, lty=2) # col="lightblue"
points( c(Mu-v*Sd,Mu-v*Sd), c(0,0.14), type='l', lty=2)
text( Mu-v*Sd, 0.17, labels=paste0(round(Mu-v*Sd, 2), " ="), cex=1.5 )
text( Mu-v*Sd, 0.15, labels=paste(Mu,"-",signif(v,3),"*",Sd,sep=""), cex=1.5 )
points( c(Mu+v*Sd,Mu+v*Sd), c(0,0.14), type='l', lty=2)
text( Mu+v*Sd, 0.17, labels=paste0(round(Mu+v*Sd, 2), " ="), cex=1.5 )
text( Mu+v*Sd, 0.15, labels=paste(Mu,"+",signif(v,3),"*",Sd,sep=""), cex=1.5 )
points( x,y, type='l', lwd=2)
text( Mu,0.10, "95%",cex=2)
text(Mu, 0.23, paste("N(",Mu,",",Sd,")",sep=""), cex=2.2 )
@
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Sampling]{Sampling, SE(M) and CLT.} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<samp_setup, cache=FALSE, include=FALSE>>=
par(mar=c(5,4,4,2)+0.1)
set_params <- function(){
   set.seed("19790424")
   Mu <<- 179
   Sd <<- 6.35
   sampleN <<- function(n) rnorm(n, mean=Mu, sd=Sd)
   x1 <<- sampleN(10)
   x2 <<- c(x1, sampleN(40))
   x3 <<- c(x2, sampleN(450))
   Min <<- min(160, min(x3))
   Max <<- max(200, max(x3))
   B <<- seq(from=145,to=215,by=2.5)
   B2 <<- seq(from=145,to=215,by=1.25)
   yMax <<- max(
      hist(x1, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density,
      hist(x2, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density,
      hist(x3, freq = F, breaks=B, plot = FALSE, warn.unused = F)$density
   )
   n <<- 10
   m <<- 5
   d <<- 0.3
   DD <<- 1.5
   COL <<- "black" # "red"
   alfa <<- 255
   wes_rgb <<- c(
      rgb(216, 183, 10,  alpha = alfa, maxColorValue = 255),
      rgb(2,   64,  27,  alpha = alfa, maxColorValue = 255),
      rgb(162, 164, 117, alpha = alfa, maxColorValue = 255),
      rgb(129, 168, 141, alpha = alfa, maxColorValue = 255),
      rgb(151, 45,  21,  alpha = alfa, maxColorValue = 255)
   )
}
par(.par_reset)
@
\frame{ % -------------------------------------------------------------------->
  \frametitle{Understanding sampling using the Seeing Theory website}
The Seeing Theory website

{\centering \href{https://seeing-theory.brown.edu/probability-distributions}
    {https://seeing-theory.brown.edu/probability-distributions}\par}

provides a way to visualize sampling (Section 'Central Limit Theorem').

\rymd
A population distribution is given (with parameters $\alpha$ and $\beta$).

\rymd
You simulate calculating a \emph{sample mean} from a sample of size $\leq 15$
up to 50 iterations at the time.

\rymd
\textbf{Note:} at sample size 1, this means just recording the value sampled.

\begin{itemize}
\item At sample size 1, with many iterations the sample distribution should
  resemble the population.
\item What happens to the distribution of the sample mean as the sample mean
  increases?
\end{itemize}

Note: in a real study we only get the one sample, so we never observe the
sampling distribution directly.

}
\frame{ % -------------------------------------------------------------------->
\frametitle{Important features of sampling}

A population has a mean $\mu$ and sd $\sigma$.

\rymd
A random (unbiased) sample will resemble the population (approximately same mean
and sd).

\rymd
But the distribution \emph{of the sample mean} is more centered
around this value $\mu$, in particular
\begin{itemize}
\item it tends to be more symmetric, and
\item has a smaller standard devation.
\end{itemize}

But again: the sample mean distribution is unobserved, so we must rely on theory
to determine its standard devation, a.k.a.\ the \textbf{standard error (of the
  mean)}.
}
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Attempt to visualize sampling from a given model}
%% \rymd Assume that height of individuals in some population
%% \begin{itemize}
%%    \item is Normally distributed,
%%    \item has mean ($\mu$) 179 (cm), and,
%%    \item has s.d. ($\sigma$) 6.35 (cm).
%% \end{itemize}

%% \rymd The following three slides show histogram of samples of sizes 10, 50 and 500, respectively.
%% }
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{$n=10$}
%% <<samp1>>=
%% set_params()
%% curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,
%%       xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
%% points(x=x1,y=rep(-0.005, length(x1)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
%% hist(x1, add=TRUE, prob=TRUE, breaks=B, col=.blue)
%% curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{$n=50$}
%% <<samp2>>=
%% set_params()
%% curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,
%%       xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
%% points(x=x2,y=rep(-0.005, length(x2)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
%% hist(x2, add=TRUE, prob=TRUE, breaks=B, col=.blue)
%% curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{$n=500$}
%% <<samp3>>=
%% set_params()
%% B <- seq(from=145,to=215,by=2.5)
%% curve(dnorm(x, mean=Mu, sd=Sd), from=Min, to=Max,
%%       xlab="Outcome", ylab="Density", ylim=c(-0.005,yMax))
%% points(x=x3,y=rep(-0.005, length(x3)), pch = 16, col = rgb(0,0,0,alpha = 0.3))
%% hist(x3, add=TRUE, prob=TRUE, breaks=B, col=.blue)
%% curve(dnorm(x,mean=Mu, sd=Sd), from=Min, to=Max,lty=2, add=TRUE)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Properties of samples and sample means}
%% Suppose we have a sample of size 10 from the population.

%% \rymd We want to know the \emph{population mean} $\mu$.

%% \rymd We can estimate $\mu$ with the \emph{sample mean} $\mu^*$.

%% \rymd If the sample is drawn \emph{at random} then $\mu^*$ is \emph{unbiased}
%% (on average correct)

%% \rymd But we also want to know its \emph{precision} - often by calculating its
%% standard deviation.

%% %% \rymd  \emph{If we knew} that the standard deviation of $\mu^* = 180$ was, say
%% %% 3.0, then there is an (approximate!) interpretation:
%% %% \begin{quotation}
%% %% The estimated value 180 (cm) is on average off by 3.0 (cm).
%% %% \end{quotation}

%% %% But what does it mean for a sample mean to have a standard deviation?

%% \rymd Consider several iterations of the procedure of drawing a sample of size 10.
%% }
%% \frame{ % -------------------------------------------------------------------->
%% %\frametitle{Properties of samples and sample means}
%% It is clear that there is variation within a sample and thus a standard deviation
%% can be calculated (directly from the sample itself) \ldots
%% <<sd>>=
%% set_params()
%% use.sd.here <- FALSE
%% MAT <- matrix( rnorm(n*m, mean=Mu, sd=Sd), ncol=n, nrow=m )
%% save(MAT, file="data/MAT.rdata")
%% if(use.sd.here) par(mar=c(5, 7, 4, 2)) else par(mar=c(5,4,4,2) + 0.1) # default c(5,4,4,2) + 0.1
%% plot( x=c(min(MAT), max(MAT)), y=c(0,m), type='n',
%%       xlab="Outcome", ylab="", yaxt='n', bty='o', xaxt = 'n',
%%       main=paste(m, "samples of size", n, "from a Normal population mean =", Mu, "and sd. = ", Sd)
%% )
%% axis(1, at = c(170,179,190))
%% abline(v=179, lty=2, col="darkgray", lwd=2)
%% if(use.sd.here) text(x=min(MAT)-DD, y=m+0.5, labels="Sample s.d.", xpd=TRUE, pos=2, offset=1)
%% for(k in 1:m){
%%    tmp <- MAT[k,]
%%    #col <- if(m<=5) wes_palette("Cavalcanti1", 5)[k]
%%    col <- if(m<=5) wes_rgb[k]
%%    mtm <- mean(tmp)
%%    sdt <- sd(tmp)
%%    if(use.sd.here) text(x=min(MAT)-DD, y=m+1-k, labels=round(sdt,1), xpd=TRUE, pos=2, offset=1)
%%    points(x=tmp, y=rep(m+1-k,n), pch=20+k, bg=col, cex = 1.5)
%% }
%% par(.par_reset)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% %\frametitle{Properties of samples and sample means}
%% \ldots \emph{but} there is also a variation associated with a sample mean (but we
%% do not tend to see it). \emph{Anything} calculated from a (random) sample
%% (e.g.\ a mean value or a regression coefficient) is a random number and thus has
%% a standard deviation (but we typically need theory to calculate this!)

%% <<sem0>>=
%% load(file="data/MAT.rdata")
%% set_params()
%% plot( x=c(min(MAT), max(MAT)), y=c(0,m), type='n',
%%       xlab="Outcome", ylab="", yaxt='n', bty='o', xaxt = 'n',
%%       main=paste(m, "samples of size", n, "from a Normal population mean =", Mu, "and sd. = ", Sd)
%% )
%% axis(1, at = c(170,179,190))
%% abline(v=179, lty=2, col="darkgray", lwd=2)
%% for(k in 1:m){
%%    tmp <- MAT[k,]
%%    #col <- if(m<=5) wes_palette("Cavalcanti1", 5)[k]
%%    col <- if(m<=5) wes_rgb[k]
%%    mtm <- mean(tmp)
%%    sdt <- sd(tmp)
%%    points(x=tmp, y=rep(m+1-k,n), pch=20+k, bg=col, cex = 1.5)
%%    points(x=mtm, y=m+1-k, cex=3, bg=col, pch=20+k, lwd=2)
%%    points(x=mtm, y=0, cex=3, bg=col, pch=20+k, lwd=2)
%%    segments(x0 = mtm, y0 = 0.3, x1 = mtm, y1 = m+0.7-k, col = col, lty = 2)
%% }
%% @
%% }


%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Properties of sample means}

%% \textbf{Standard Error of the Mean (SEM)}\\
%% The standard deviation of the sample mean is referred to
%% as SEM and a measure
%% of (approx.) the average distance the population mean.
%% Thus a measure of the precision the sample mean is as
%% an estimator of the population mean.

%% \rymd In a Normal model the SEM is the population s.d. dived
%% by $\sqrt n$.

%% \rymd \textbf{Standard Errors (SE)}\\
%% More generally, the standard deviation of something calculated from a sample is
%% called its standard error.

%% \rymd Later we will use these to create \emph{confidence intervalls}.

%% }
%% \frame{ % -------------------------------------------------------------------->
%% %\frametitle{Properties of samples and sample means}
%% <<sem>>=
%% load(file="data/MAT.rdata")
%% set_params()
%% par(mar=c(5, 7, 4, 2) )# default c(5,4,4,2) + 0.1
%% plot( x=c(min(MAT), max(MAT)), y=c(0,m), type='n',
%%       xlab="Outcome", ylab="", yaxt='n', bty='o', xaxt = 'n',
%%       main=paste(m, "samples of size", n, "with population mean =", Mu, "and sd. = ", Sd)
%% )
%% axis(1, at = c(170,179,190))
%% abline(v=179, lty=2, col="darkgray", lwd=2)
%% text(x=min(MAT)-DD, y=m+0.5, labels="Sample s.d.", xpd=TRUE, pos=2, offset=1)
%% for(k in 1:m){
%%    tmp <- MAT[k,]
%%    #col <- if(m<=5) wes_palette("Cavalcanti1", 5)[k]
%%    col <- if(m<=5) wes_rgb[k]
%%    mtm <- mean(tmp)
%%    sdt <- sd(tmp)
%%    text(x=min(MAT)-DD, y=m+1-k, labels=round(sdt,1), xpd=TRUE, pos=2, offset=1)
%%    points(x=tmp, y=rep(m+1-k,n), pch=20+k, bg=col, cex = 1.5)
%%    points(x=mtm, y=m+1-k, cex=3, bg=col, pch=20+k, lwd=2)
%%    points(x=mtm, y=0, cex=3, bg=col, pch=20+k, lwd=2)
%%    segments(x0 = mtm, y0 = 0.3, x1 = mtm, y1 = m+0.7-k, col = col, lty = 2)
%% }
%% tmp <- rowMeans(MAT)
%% mtm <- mean(tmp)
%% text(x=min(MAT)-DD, y=0, labels=paste("SEM ~",round(sd(tmp),1)), xpd=TRUE, pos=2, offset=1, col=COL, cex=1.2)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% In this example we can exactly specify the distribution of the sample mean.
%% <<pop_and_mean>>=
%% set_params()
%% curve(dnorm(x,Mu,Sd), from=min(MAT),to=max(MAT), ylim=c(0,0.20), ylab="Density",
%%       xlab="", lty=1, lwd=2, xaxt = 'n')
%% axis(1, at = c(170, 179, 190))
%% curve(dnorm(x,Mu,Sd/sqrt(10)), from=165,to=195, add=TRUE, lty=2, lwd=2)
%% legend("topleft",
%%        legend=c(expression(N(mu, sigma) - population),
%%                 expression(N(mu,sigma/sqrt(10)) - `sample mean`),
%%                 expression(mu==`179.0`,sigma==6.35)),
%%        title="Distribution of:", lty=c(1:2,0,0), lwd=c(2,2,0,0), bty='n', cex=1.5)
%% @
%% }
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Normal population $\Rightarrow$ Normal mean}
%% On the previous slide you saw
%% \begin{itemize}
%%    \item a Normal population curve, and
%%    \item the Normal curve for the sample mean (for sample size 10).
%% \end{itemize}

%% \rymd
%% In this case this is the true (derived from theory) density
%% curve for the sample mean.

%% \rymd
%% Properties of the Normal distribution will aid further analysis
%% using the mean of the sample.

%% \rymd
%% What happens if the population follows some non-Normal
%% curve?
%% }
\frame{ % -------------------------------------------------------------------->
\frametitle{The Central Limit Theorem (CLT)}

\textbf{CLT:} Regardless of the population density curve, the sample mean
density can be made (with arbitrarily good approximation) Normal by choosing $n$
large enough.

\begin{itemize}
   \item How large does $n$ have to be? \\Depends on how skew the population density is. \\
      \begin{itemize}
         \item In general $n=20$ will suffice.
         \item If population is Normal then $n=1$ is enough.
      \end{itemize}
   \item CLT applies to many 'statistics' (= functions of samples).
\end{itemize}

\rymd
The next 2 slides shows theoretical distributions for a population and sample
means thereof, for varying sample sizes.
}

\frame{ % -------------------------------------------------------------------->
\frametitle{Visualization of sample mean from normal population}
The distribution of sample means from a \emph{normal} distribution. In this case
the sample mean \emph{is normally distributed} (but with a smaller sd).

<<norm_mean>>=
COL <- wes_palette("Cavalcanti1", 5) #brewer.pal(5, "Set2")
par(mar=c(4,4,1,1))
plot(1,1,type='n', xlim=c(0,2.5), ylim=c(0,1.8), xlab="Outcome", ylab="Density")
ns <- c(1,2,5,10,20)
for(k in 1:5){
   n <- ns[k]
   curve(dnorm(x, mean=1, sd = 1/sqrt(n)), from=-.5, to=5, add=TRUE, lty=k, col=COL[k], lwd=2)
}
abline(v=1, col="grey", lwd=1, lty=1)
legend("topright", legend=c("1 (Population)", ns[-1]), col=COL, lwd=2, lty=1:4, title="Sample size", bty='n', cex=1.5)
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Attempt to visualize CLT for the sample mean}
The distribution of sample means from a skewed distribution. The sample mean is
\emph{not} normally distributed, but increasingly so.
<<exp_mean>>=
COL <- wes_palette("Cavalcanti1", 5) #brewer.pal(5, "Set2")
par(mar=c(4,4,1,1))
plot(1,1,type='n', xlim=c(0,2.5), ylim=c(0,1.8), xlab="Outcome", ylab="Density")
ns <- c(1,2,5,10,20)
for(k in 1:5){
   n <- ns[k]
   curve(n*dgamma(x*n, shape=n), from=0, to=5, add=TRUE, lty=k, col=COL[k], lwd=2)
}
abline(v=1, col="grey", lwd=1, lty=1)
legend("topright", legend=c("1 (Population)", ns[-1]), col=COL, lwd=2, lty=1:4, title="Sample size", bty='n', cex=1.5)
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{The $t$-distribution}

Calculating standard test statistics from a normal distribution requires
estimating the standard deviation. For \textbf{small samples} the change in
distribution motivates making exact calculations. The $t$-distribution is
"increasingly normal" as its parameter (degrees of freedom) increases.

<<"t-dist", include = TRUE>>=
par(mar = c(5.1, 4.1, 4.1, 2.1))
x0 <- 4
curve(dnorm(x, 0, 1), -x0, x0, col = "grey", cex = 2, ylab = "Density", xlab = "")
## text(0, dnorm(0), expression(infinity), adj = c(0.5,-.3))
curve(dt(x, df = 1), -x0, x0, add = T, col = "black")
## text(0, dt(0, df=1), "1", adj = c(0.5,-.3))
curve(dt(x, df = 3), -x0, x0, add = T, col = "red")
## text(0, dt(0, df=3), "3", adj = c(0.5,-.3))
curve(dt(x, df = 7), -x0, x0, add = T, col = "blue")
## text(0, dt(0,df=7), "7", adj = c(0.5,-.3))
legend(x = -4, y = .4, legend = c(1, 3, 7, expression(infinity == "N(0,1)")), lty = 1,
       col = c("black", "red", "blue", "grey"), title = "Degrees of freedom")
par(.par_reset)
@

}
\frame{ % -------------------------------------------------------------------->
\frametitle{The $\chi^2$-distribution}

If you add $k$ standard normal random numbers, each squared, then the resulting
distribution is $\chi^2(k)$. As we will see this is useful in the context of
categorical variables.

<<"chi2-dist", include = TRUE>>=
x0 <- 8
curve(dnorm(x, 0, 1), -3, x0, col = "grey", xlim = c(-2,7))
curve(dchisq(x, df = 1), 0, x0, add = T, col = "black")
## text(0.5, dchisq(0.5, df=1), "1", adj = c(0.5,-.3))
curve(dchisq(x, df = 3), 0, x0, add = T, col = "red")
## text(1.1, dchisq(1.1, df=2), "2", adj = c(0.5,-.3))
curve(dchisq(x, df = 7), 0, x0, add = T, col = "blue")
## text(3.5, dchisq(3.5,df=3), "3", adj = c(0.5,-.3))
legend(x = 3, y = .4,
       legend = c(expression("N(0,1)"),
                  expression(chi~"(1)"),
                  expression(chi~"(3)"),
                  expression(chi~"(7)")),
       lty = 1,
       col = c("grey", "black", "red", "blue"), title = "Distribution")
@
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Visual tests]{Visual tests (of normality)} %%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{Visual tests of normality}
Perhaps surprisingly, quite often we rely on \emph{visual} rather than
\emph{formal} tests of model assumptions.

\rymd
A common formal test of normality is the Shapiro-Wilks test.

\rymd Many plots can provide a visual test of normality, but a common one is the
Q-Q plot. 'Q' is for \emph{quantile}.

\rymd
\textbf{Quantile?}
Quantiles divides your data into (roughly) equal piles.
\begin{itemize}
\item the median is the 2-quantile
\item the tertiles are the 3-quantiles (the $33\frac 13$ percentile and
the $66\frac 23$ percentile)
\item the quartiles (Q1, Q2 and Q3) are the 4-quantiles.
\item \ldots and so on.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Cross-over data}
13 patients had their peak expiratory flow (PEF, l/min) recorded
once after inhaling each of two different asthma drugs
(the order of which were random).

\rymda In \emph{paired} data one usually look at the 13 differences as a measurement
of effect size.

\rymda Data:
\[ \mbox{\Sexpr{load("data/F4_crossover.Rdata"); paste(y-x, collapse=",\\,\\,")}} \]
Is the normal distribution a good model for these 13 numbers?
}
\frame{ % -------------------------------------------------------------------->
\frametitle{PEV}
A histogram with best normal density fit.
<<pev_h, cache=FALSE>>=
load("data/F4_crossover.Rdata")
par(mar=c(4,4,0,0))
curve( dnorm(t, mean(y-x), sd(y-x)), from=-60, to=160, ylim=c(0,.016), lty=1, xname="t", xlab="Differences (formoterol-sabutamol) L/min", main="", ylab = "Density", xlim = c(-50, 150))
hist(y-x, freq=FALSE, breaks=seq(-50,150,len=10),  xlim=c(-60,160), ylim=c(0,.018),  col=.blue, add = TRUE)
curve( dnorm(t, mean(y-x), sd(y-x)), from=-50, to=150, lty=2, add=TRUE, xname="t")
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{PEV}
A cumulative frequency with best normal density fit.
<<pev_ecdf>>=
load("data/F4_crossover.Rdata")
par(mar=c(4,3,0,0))
plot(ecdf(y-x), verticals=TRUE, do.points=FALSE,
     xlab="Differences (formoterol-sabutamol) L/min", ylab="",
     xlim=c(-100,200), main="")
curve( pnorm(t, mean(y-x), sd(y-x)), from=-250, to=200, lty=2, add=TRUE, xname="t")
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{The Quantile-Quantile plot}

If the effect size is Normally distributed its QQ-plot should be a straight line
(approximately).

A QQ-plot plots the sample (of size $n$) against the %(slightly shifted)
$n$-quantiles of the (standard) Normal distribution.

<<pev_qq, cache=FALSE>>=
load("data/F4_crossover.Rdata") # x (salbutamol), y (formoterol)
par(mar=c(4,4,4,4))
qqnorm(y-x)
qqline(y-x, col="grey70")
par(.par_reset)
@
}
\frame{ % -------------------------------------------------------------------->
The S100$\beta$ measurements is certainly not normally distributed.
<<sub_norm>>=
load("data/F10B_subarach.Rdata")
t <- dd$s100b
layout(matrix(1:2, ncol=2))
plot(ecdf(t), do.points=FALSE, verticals=TRUE, xlab="micrgrams / litre", ylab="", main="CF")
curve(pnorm(x, mean(t), sd(t)), from=-1, to=2, add=TRUE, lty=2, col="grey60")
qqnorm(t, ylim=c(-0.2, 1.2))
qqline(t)
@
}
\frame{ %  ------------------------------------------------------------------->
\frametitle{A reminder ahead of time}
\begin{center}
\fbox{\textbf{It is very rarely the actual data that is tested for normality!}}
\end{center}
Most of the time the models that assume normality does so for the \emph{error terms},
i.e.\ there is a model, depending on the covariates $x$, for the outcome
$Y$ such that
\[ Y = \mbox{some deterministic function of x} + \mbox{random error}. \]

E.g.\ a 2-sample $t$-test assumes that an outcome is normally distributed around a
group-specific mean. Data for such a test might look like this

\begin{center}\begin{tabular}{|c|rrrrrr} \hline
 outcome ($Y$) & 5.1 & 6.2 & 7.9 & 9.2 & 4.7 & $\ldots$ \\
 group ($x$)   &   A &   A &   B &   B &   A & $\ldots$ \\ \hline
\end{tabular}\end{center}

We cannot test the entire $Y$ data for normality. This is evident if imagine the
group effect to be very large\ldots
}
\frame{ %  ------------------------------------------------------------------->
<<fig.height = 2.7>>=
n <- 250
a_mean <- 6
b_mean <- 10
set.seed(12345678)
df <- data.frame(
    x = rep(LETTERS[1:2], each = n),
    Y = rnorm(2*n, rep(c(a_mean,b_mean), each = n), 1)
)
df$resid = df$Y - ifelse(df$x=="A", a_mean, b_mean)
ggplot(df, aes(Y, fill = x)) +
    geom_histogram(aes(y = ..density..), binwidth = 0.75, alpha = 1/2) +
    stat_function(fun = dnorm, size = 1, lty = 2,
                  args = list(mean = a_mean)) +
    stat_function(fun = dnorm, size = 1, lty = 2,
                  args = list(mean = b_mean)) +
    scale_fill_manual(values = c(.green, .red)) +
    labs(x = "Outcome (Y)", y = "Density") +
    theme_bw()
@

It is the deviations (noise/error term) around each group-specific mean that
is supposed to be normal, an estimation of which is called \emph{residuals}.
Subtract the (estimated) group effect from each datapoint to get:

<<fig.height = 2.7>>=
ggplot(df, aes(resid)) +
    geom_histogram(aes(y=..density../2, fill = x), binwidth = 0.5, alpha = 1/2) +
    labs(x = "Residual", y = "Density") +
    scale_fill_manual(values = c(.green, .red)) +
    stat_function(fun = dnorm, size = 1, lty = 2) +
    theme_bw()
@

}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{$\phantom{.}$} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{Second Summary}
%% 95\% of observations from a Normal population lies within
%% 1.96 multiples of the (population) s.d.  from the (population)
%% mean.

%% \rymd Means and, in particular sd's, must be distinguished on three levels
%% \begin{itemize}
%% \item population,
%% \item sample, and
%% \item estimate.
%% \end{itemize}

%% \rymd The s.d. of the latter is called the Standard Error\\

%% \rymd The CLT explains why many estimates ('statistics') are
%% (approx.) Normally distributed even though the population
%% may not be.
%% }
\frame{ % -------------------------------------------------------------------->
\frametitle{References}
\begin{itemize}
\item Chapters 1-8, 10: Petrie \& Sabin. \emph{Medical Statistics at a Glance}, Wiley-Blackwell (2009).
\item Puhan et al. \emph{More medical journals should inform their contributors about three
key principles of graph construction}, Journal of Clinical Epidemiology,
\textbf{59} (2006) 1017-1022.
\item Franzblau \& Chung. \emph{Graphs, Tables, and Figures in Scientific Publications: The
Good, the Bad, and How Not to Be the Latter}, American Society for Surgery of the Hand,
\textbf{37A} (2012) 591-596.
\item Kelleher \& Wagener. \emph{Ten guidelines for effective data visualization in scientific
publications}, Environmental Modelling \& Software \textbf{26} (2011) 822-827.
\item L.\ Wilkinson, \emph{The Grammar of Graphics}, 2$^{\mbox{nd}}$ ed., Springer 2005.
%\item H. Wickham, \emph{ggplot2}, 2$^{\mbox{nd}}$ ed. TO APPEAR
\end{itemize}
}
\newcommand{\lada}{\fbox{$\phantom{x}$}}
\frame{ % -------------------------------------------------------------------->
\frametitle{First poll}
\textbf{Q1:} Tick the boxes you think are always true.
\begin{itemize}
\item[\lada] An ordinal variable with values A, B, C, (etc) is such that the "increases" (although not numerical) B-A, C-B, (etc) can be considered to be of the same magnitude.
\item[\lada] Anything measured numerically must be analysed as such.
\item[\lada] Anything recorded as a categorization must be analysed as such.
\end{itemize}

\textbf{Q2:} A group of 24 individuals have been randomly assigned to 6 different exercise groups, and their blood pressure is measured after training. The researchers do a boxplot for the measurements for each group. Is this a good approach?
\begin{itemize}
\item[\lada] Yes, a good way to visualize the overall pattern.
\item[\lada] No, the overall sample size is too small.
\item[\lada] No, the group sizes are too small.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Second poll}
\textbf{Question ?:}
\begin{itemize}
\item[\lada] text
\item[\lada] text
\item[\lada] text
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Third poll}
\textbf{Question ?} The Law of Large numbers state that the relative frequency
of an event must tend to its true probability.
\begin{itemize}
\item[\lada] text
\item[\lada] text
\item[\lada] text
\end{itemize}
\textbf{Question ?} Something to do with the central limit theorem.
\begin{itemize}
\item[\lada] text
\item[\lada] text
\item[\lada] text
\end{itemize}
}

\end{document} % <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


%% \frame{ % -------------------------------------------------------------------->
%%   \frametitle{poll}
%%   \newcommand{\lada}{\fbox{$\phantom{x}$}}
%% \textbf{Question ?:}
%% \begin{itemize}
%% \item[\lada] text
%% \item[\lada] text
%% \item[\lada] text
%% \end{itemize}
%% }
