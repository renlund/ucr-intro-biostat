<<PRES_OR_HANDOUTS, cache=FALSE, echo=FALSE, include=TRUE, results='asis'>>=
if(!exists("HANDOUT")) HANDOUT <- FALSE
if(HANDOUT){
   cat("
\\documentclass[handout]{beamer}
\\usepackage{pgf,pgfpages}
\\pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=0.5in]
")
} else {
   cat("\\documentclass{beamer}")
}
rm(HANDOUT)
@

\usepackage{beamerthemeclassic}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{multicol}
\usepackage{multirow}

\newcommand{\plot}{0.42}
\newcommand{\pr}{\mathbf{Prob}}
\newcommand{\el}{\mbox{\;or\;}}
\newcommand{\rymd}{\vspace{0.3cm}}
\newcommand{\rymda}{\vspace{0.5cm}}

%\setbeamersize{text margin left=6mm, text margin right=2mm}  % DEFAULT
\setbeamersize{text margin left=3mm, text margin right=2mm}

\title{Introduction to Biostatistics \\ Lecture 6}
\author{Henrik Renlund}
\date{Fall 2020}

<<"colors", cache=FALSE, echo=FALSE, include=FALSE>>=
.yellow <- wes_palette("Cavalcanti1", 5)[1]
.green <- wes_palette("Cavalcanti1", 5)[2]
.grey <- wes_palette("Cavalcanti1", 5)[3]
.blue <- wes_palette("Cavalcanti1", 5)[4]
.red <- wes_palette("Cavalcanti1", 5)[5]
.seq3 <- brewer.pal(5,"YlGn")[2:4]
@


\begin{document} % >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

\frame{ % -------------------------------------------------------------------->
\begin{center}
\includegraphics[scale=0.24]{pics/Tote_Board.jpg}
\end{center}
\begin{flushright}
 {\tiny
  "Tote Board, Hollywood Park, Century, Inglewood, CA, US" by jondoeforty1\\
  \url{http://www.flickr.com/photos/jondoeforty1/2602455841/}\\
  Licensed under CC BY 2.0 via Commons\\
  %\url{https://commons.wikimedia.org/wiki}
 }
\end{flushright}
}
\frame{ % -------------------------------------------------------------------->
\titlepage
\begin{center}
\includegraphics[scale=0.2]{pics/ucrlogo.pdf}
\end{center}
}
% \frame{ % -------------------------------------------------------------------->
% \frametitle{Contents of Lecture 1-2}
% \tableofcontents
% }
\frame{ % -------------------------------------------------------------------->
\frametitle{What shall we learn today?}

Many analyses and concepts that relates to count data (tables), in particular
odds.

\rymd An overly optimistic description: Lectures 3-5 but for categorical, rather than numerical, data.

\rymd For tables relating counts of a categorical variable,
how can we test the distribution of values against
\begin{itemize}
   \item a model (probability function), or
   \item between subgroups.
\end{itemize}

\rymd We will start with the special case of dichotomous/binary data (event or non-event).
}
\frame{ % -------------------------------------------------------------------->
\frametitle{A note on categorical data}
We generally talk differently about categorical data depending on the number of unique values.

\rymd \textbf{Dichotomous/binary data} is typically yes/no- or event/non-event data.
We talk about this data in terms of the probability of one of the events (often the one with the smallest probability). If $\pr($event$)$ is modelled, then $\pr($non-event$)$ is implicit (since $\pr($non-event)=1-$\pr($event$)$).

\rymd \textbf{"Non-binary" categorical data} has more than 2 values ($A$, $B$, $C$, \ldots). We talk about this data in terms of the entire \emph{distribution}, i.e. the probability function $(\pr(A), \pr(B), \pr(C), \ldots)$. Of course we could omit one of these, since it would be implicit, but it is unconvenient.
}
\frame{ % -------------------------------------------------------------------->
  \frametitle{Numeric data verses categorical}
  \textbf{1 sample:}

  \rymd Suppose $x_1, x_2, \ldots, x_n$ is a sample from some population.

  \rymd \emph{Numeric:} population mean $ = \mu$? Answered by 1-sample
  $t$-test (parametric) or Wilcoxon signed rank test (non-parametric).

  \rymd \emph{Categorical:} is the probability
  function $ = p(k)$? Or, if binary, is $\pr$(event) = $p$?
  Answered by e.g.\ confidence interval for $p$ or $\chi^2-test$.

  \rymd \textbf{(2-sample paired:)}

  \rymd \emph{Numeric:} taking differences reduces this to the 1-sample situation.

  \rymd \emph{Categorical:}  McNemars test.

}
\frame{ % -------------------------------------------------------------------->
  \frametitle{Numeric data verses categorical}
  \textbf{2 samples:}

  \rymd Suppose $x_1, x_2, \ldots, x_n$ and $y_1, y_2, \ldots, y_n$ are samples
  from possibly different populations.

  \rymd \emph{Numeric:} Are the population means the same? Answered by 2-sample
  $t$-test (parametric) or Mann-Whitney (non-parametric).

  \rymd \emph{Categorical:} are the probability
  function the same? Or, if binary, is $\pr$(event) the same?
  Answered by Fishers exact test or $\chi^2$-test.

  \rymd \textbf{Many samples:}

  \rymd \emph{Numeric:} All means the same? Answered by ANOVA (parametric) or Kruskal-Wallis (non-parametric)

  \rymd \emph{Categorical:} Are all probability functions the same? Answered by $\chi^2$-test.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Risk measures]{Risk measures and their estimates} %%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{Dabigatran data}
Dagbigatran is an anticoagulant used for e.g.\
stroke prevention in patients with atrial fibrillation.
\emph{The following example only looks at side effects.}

\rymd 718 people were randomized to Dabigatran or placebo
and observed for some set time for bleeding.

\begin{center}
\begin{tabular}{ccc}
id & intervention & bleeding \\ \hline \hline
1 & dabigatran & Yes \\
2 & placebo & No \\
3 & placebo & No \\
4 & dabigatran & No \\
$\vdots$ & $\vdots$ & $\vdots$ \\
718 & placebo & No \\ \hline
\end{tabular}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Tabulated data}
\begin{center}
\begin{tabular}{c|cc||c}
\multicolumn{1}{c}{}  & \multicolumn{2}{c}{Bleeding} & \\
    & Yes & No & Sum\\ \hline
dabigatran & 27  & 320 & 347 \\
placebo & 8 & 363 & 371 \\ \hline \hline
Sum & 35 & 683 & 718 \\
\end{tabular}
\end{center}
Measures for dabigatran:
\begin{itemize}
\item \textbf{Risk} (probability of an unwanted event) \\
Risk of bleeding $= 27/347 = 0.078$
\item \textbf{Odds} (how much more likely it is, versus not, to
experience an event)\\
Odds of bleeding
\[ = \frac{27/347}{320/347} = \frac{27}{320} = 0.084 \]
\end{itemize}
(Odds? Sometimes this is easier to model.)
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Odds}
For an event with probability $p$, the odds is $p/(1-p)$.
<<odds_1>>=
par(mar=c(4,4.1,1,1), "ylog"=TRUE)
curve(x/(1-x), from=0, to=1, ylab="Odds", xlab="Probability", lwd=2,
   cex.lab=1.5, las=1, yaxp=c(0,100,4))
@
}

\frame{ % -------------------------------------------------------------------->
\frametitle{Odds}
For small probabilities: odds $\approx$ probability.
<<odds_2, fig.height = 5>>=
par(mar=c(4,4.1,1,1))
curve(x/(1-x), from=0, to=0.75, ylab="Odds", xlab="Probability", lwd=2,
   xaxt='n', yaxt='n',xlim=c(0,0.667), ylim=c(0,2), cex.lab=1.5)
axis(side=1,at=c(0,0.1,1/3, 0.5,2/3), labels=c("0", "0.1", "1/3", "1/2", "2/3"))
axis(side=2,at=c(0,1/2,1,2), labels=c("0","1/2","1","2"), las=1)
abline(a=0, b=1, lty=3, col="blue", lwd=2)
text(x=7/12,y=7/12,labels="y=x",pos=3,srt=11, cex=1.5)
LTY <- 2
COL <- "gray"
X <- c(1/3,1/2,2/3)
Y <- c(1/2,1,2)
for(k in seq_along(X)){
   x <- X[k]; y <- Y[k]
   points(x=x,y=y)
   points(x=c(x,x),y=c(0,y), type="l",lty=LTY, col=COL)
   points(x=c(0,x), y=c(y,y), type="l",lty=LTY, col=COL)
}
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{A few remarks on odds}
\begin{itemize}
   \item if an event has odds $\theta$, then its probability $p$ is $p=\theta/(1+\theta)$ \\
      E.g. \begin{itemize}
              \item $\theta = 2$ corresponds to $p=2/3$. \\
              \item $\theta = 1$ corresponds to $p=1/2$. \\
              \item $\theta = 1/100$ corresponds to $p=1/101$.
           \end{itemize}

   \rymd \item there are multiple systems of betting (sports) 'odds', that are not odds in the sense of this course!

   \rymd \item in a betting game where you stand to win 1 unit of money, your stake $S$ (\emph{if this is kept when winning}) should not exceed the odds
      \begin{itemize}
         \item 'expected' profit $=1p-S(1-p)\geq 0$ is equivalent to $S\leq\frac{p}{1-p}=\theta$
         \item E.g.\ if you are offered $x$ units of money for a game you think has odds 2 (in your favor) then do not bet more than $2x$. \\ (Betting $2x$ makes the game \emph{fair}.)
      \end{itemize}
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Relational measures}
\begin{center}
\begin{tabular}{c|cc||c}
\multicolumn{1}{c}{}  & \multicolumn{2}{c}{Bleeding} & \\
    & Yes & No & Sum\\ \hline
dabigatran & 27  & 320 & 347 \\
placebo & 8 & 363 & 371 \\ \hline \hline
Sum & 35 & 683 & 718 \\
\end{tabular}
\end{center}
Measures for risk of dabigatran versus placebo
\begin{itemize}
\item (\textbf{Risk ratio (RR)} $ = \frac{27/347}{8/371} \approx 3.6$)
\item \textbf{Odds ratio (OR)} $ = \frac{27/320}{8/363} \approx 3.8$
\item \textbf{Risk difference} $= 27/347 - 8/371 \approx 0.056$
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Odds ratio (OR)}
Probabilities cannot be retrieved from the OR alone.

\textbf{N.B.}
\begin{itemize}
  \item Odds = 1 means p = 0.5 (as likely to experience the event as to not
experience the event)
 \item OR = 1 means events are equally likely in both groups
\end{itemize}

\vspace{0.2cm}
If you know the 'denominator' probability ($p_2$) then the 'numerator'
probability ($p_1$) can be calculated
\[ p_1 = \frac{\text{OR}\cdot p_2}{1+(\text{OR}-1)\cdot p_2}. \]

For small values of $p_2$ and 'moderate' values of OR
\[ p_1 \approx \text{OR}\cdot p_2, \]
i.e.
\[ \text{OR} \approx \frac{p1}{p2} = \text{RR}. \]

% Deviation (\%) between approximation and exact formula:
<<tab_odds, results='asis', eval = FALSE>>=
## THE <- c(0.1, 0.5, 1, 2, 10)
## #xs <- c(0.75, 0.55, 0.47, 0.4, 0.23)
## ps <- c(0.01, 0.05, 0.1, 0.5)
## M <- matrix(NA, nrow=length(ps), ncol=length(THE))
## L <- matrix(NA, nrow=length(ps), ncol=length(THE))
## rownames(M) <- sprintf("%d %%", 100*ps)
## colnames(M) <- THE
## for(i in 1:length(ps)){
##    for(j in 1:length(THE)){
##       M[i,j] <- THE[j]*ps[i]/(1+(THE[j]-1)*ps[i])
##       L[i,j] <- THE[j]*ps[i]
##    }
## }
## latex(
##    signif(100*(L-M)/M,2),
##    file="",
##    title="'denominator' ($p_2$)",
##    caption.loc="bottom",
##    cgroup="Odds Ratio (OR)"#,
##    #rowlabel="'denominator'"
##   )
@
}
% \frame{ % -------------------------------------------------------------------->
% \frametitle{OR and probabilities}
% The blue dotted lines are the approximations.
<<OR, fig.width=7, fig.height=7, include=FALSE, eval = FALSE>>=
## par(mar=c(4,4.2,1,1))
## THE <- c(0.1, 0.5, 1, 2, 10)
## xs <- c(0.75, 0.55, 0.47, 0.4, 0.23)
## plot(1,1,type='n', xlim=0:1, ylim=0:1,
##          xlab="Probability of 'denominator event'",
##       ylab="Probability of 'numerator' event",
##    cex.lab=1.5, las=1)
## for(k in seq_along(THE)){
##    curve(THE[k]*x/(1+(THE[k]-1)*x), from=0, to=1,add=TRUE, lwd=2)
##    text(x=xs[k], y=THE[k]*xs[k]/(1+(THE[k]-1)*xs[k]), label=paste("OR =", THE[k]), srt=45, cex=1.2, pos=3)
##    abline(a=0, b=THE[k], col="blue", lty=2)
## }
@
% \begin{center} \includegraphics[scale=0.4]{figure/OR-1} \end{center}
% }
\frame{ % -------------------------------------------------------------------->
\frametitle{Fishers exact test}
\begin{center}
\begin{tabular}{c|cc||c}
\multicolumn{1}{c}{}  & \multicolumn{2}{c}{Bleeding} & \\
    & Yes & No & Sum\\ \hline
dabigatran & X  & (347-X) & 347 \\
placebo & (35-X) & (683-347+X) & 371 \\ \hline \hline
Sum & 35 & (683) & 718 \\
\end{tabular}
\end{center}
Suppose that whether a person bleeds or not is complete
independent of intervention. ($H_0$: "odds ratio = 1".)

\rymd Then the 35 individuals who bled should be a random sample
of the study population (of size 718) and we would expect
that $X/35=347/718\approx 48\%$.

\rymd We would expect $X$ to be around 17, but is $X = 27$ within some acceptable range of possiblities?
}
\frame{ % -------------------------------------------------------------------->
<<approx-fisher, cache = FALSE>>=
set.seed(201107253)
x <- rhyper(500, 347, 371, 35)
@
Simulate (500 times) the experiment of randomly selecting 35 people from the study population and record the number who got dabigatran (\Sexpr{paste0(x[1:5], collapse = ", ")}\ldots)
<<approx-fisher-plot, include = TRUE, fig.height = 4>>=
#hist(x, breaks = 4:30, xlab = "Assigned Dabigatran (if $H_0$ true)", freq = FALSE, main = "")
y <- factor(x, levels = 4:30)
barplot(table(y)/length(y),  xlab = "Assigned Dabigatran", ylab = "Probability",
        main = "", space = 0, xaxt = 'n')
   axis(1, at = seq(1.5,27.5,5), tick = TRUE, labels = seq(5,30,5))
@
However, we can calculate \emph{exactly} what the distribution
of $X$ is \emph{given} $H_0$ (in this case).

\rymd The $p$-value is the probability of a discrepancy
the size of that between the observed and the expected.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{$p$-value in Fishers exact test}
<<fisher, cache=FALSE, include=FALSE>>=
bord <- matrix(c(27,320,8,363), byrow=TRUE, ncol=2)
rownames(bord) <- c("dabigatran","placebo")
colnames(bord) <- c("yes", "no")
bord
(fb <- fisher.test(bord))
fishers_p <- fb$pvalue
rm(bord, fb)
@
Sum the yellow values to get $p=0.00045$. % <------------------------------------------ \Sexpr here?
<<hyper, fig.height = 5>>=
par(mar=c(4,4.1,1,1))
xx <- 4:30
plot(xx, dhyper(xx, 347, 371, 35), type='h', xlab="Outcome", ylab="Probability",
   ylim=c(0,0.17), cex.lab=1.5, las=1)
points(8:26, dhyper(8:26,347, 371, 35), pch=16)
points(17, dhyper(17,347, 371, 35), pch=4, cex=1.7, lwd=3)
text(17, dhyper(17,347, 371, 35), pos=3, label="Mean under H0", offset=1, cex=1.5)
points(c(4:7,27:30), dhyper(c(4:7,27:30),347, 371, 35), pch=16, col=.yellow)
points(27, dhyper(27,347, 371, 35), pch=4, cex=1.7, col=.yellow, lwd=3)
text(27, dhyper(27,347, 371, 35), pos=3, col=.yellow, label="Observed", offset=2, cex=1.5)
arrows(x0=17.5, y0=dhyper(17,347, 371, 35),x1=26.5, y1=dhyper(17,347, 371, 35))
abline(v=27, lty=2, col=.yellow)
arrows(x0=16.5, y0=dhyper(17,347, 371, 35),x1=7.5, y1=dhyper(17,347, 371, 35))
abline(v=7, lty=2, col=.yellow)
text(x=23.5, y=dhyper(17,347, 371, 35), pos=3, label="Discrepancy")

## d <- 6; p <- sum(dhyper((17-d):(17+d), 347, 371, 35) )
## arrows(x0=(17-d), x1=(17+d), y0=0.155, y1=0.155, code=3)
## text(17, 0.155, pos=3, label=paste(round(100*p,1), "%", sep=""))
## d <- 5; p <- sum(dhyper((17-d):(17+d), 347, 371, 35) )
## arrows(x0=(17-d), x1=(17+d), y0=0.165, y1=0.165, code=3)
## text(17, 0.165, pos=3, label=paste(round(100*p,1), "%", sep=""))
@
}
\begin{frame}[fragile] % ----------------------------------------------------->
\frametitle{More on Fishers exact test}
My software produced the following output:
\begin{verbatim}
   Fisher's Exact Test for Count Data

data:  Dabigatran_example
p-value = 0.0004458
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 1.659358 9.877595
sample estimates:
odds ratio
  3.821942
\end{verbatim}
So odds ratio is between 1.7 and 9.9. (Allows for hypothesis testing.)\\
Probabilities are small, so risk of dabigatran is (approx.) between
1.7 and 9.9 times larger than placebo risk.
\end{frame}
% \frame{ % -------------------------------------------------------------------->
% \frametitle{Risk Ratio?}
% So
% \begin{quote}
% The odds ratio of bleeding with dabigatran \\ versus placebo is 3.8 (1.7--9.9).
% \end{quote}

% The placebo risk is $p_2=8/371\approx 2.2\%$ so we can use an earlier formula to get $p_1=$ (risk with dabigatran) and thus the RR:

% \begin{center}\begin{tabular}{|c|lll|} \hline
% OR & 1.7 & 3.8 & 9.9 \\ \hline
% %$p_1\approx$  & 3.6\% & 8.2\% & 21\% \\ \hline
% $p_1 =$ & 3.5\% & 7.8\% & 18\% \\ \hline
% RR $=$ & 1.6 & 3.6 & 8.3 \\ \hline
% \end{tabular}\end{center}
% So
% \begin{quote}
% The risk ratio of bleeding with dabigatran \\ versus placebo is 3.6 (1.6--8.3).
% \end{quote}
% (\textbf{N.B} The implied confidence interval (above) for $p_1$ is "too wide"
% since it takes to much uncertainty into account.)
% }
\frame{ % -------------------------------------------------------------------->
\frametitle{Absolute risk}
What can we say about the \emph{absolut} risk of bleeding with dabigatran?

\rymd This was covered by Lars in Lecture 3! (Genotype example.)

\rymd The risk estimate $27/347=0.078$ has a standard error (SE) given by
   \[ \sqrt{\frac{0.078(1-0.078)}{347}}=0.0144. \]

This yields a 95\% confidence interval given by
   \[ (0.078\pm 1.96\cdot 0.0144)=(0.050, 0.11). \]

   (This allows for hypothesis testing.)

\vspace{0.3cm}
\fbox{\textbf{Rule of thumb:  $n*\min(p,1-p)\geq 5$}.}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Risk difference}
What is the \emph{difference} in risk between dabigatran
and placebo?

This has (almost) been covered by Lars. One needs to know that for two \textbf{independent}  estimators (having SE$_1$ and SE$_2$) the SE for their difference is given by
   \[ \sqrt{\text{SE}_1^2+\text{SE}_2^2}. \]

\begin{center}\begin{tabular}{crr}
Risk  & Estimate & Standard error \\ \hline
dabigatran & $p_1 = 27/347 = 0.078$ & $\sqrt{p_1(1-p_1)/347}=0.0144$ \\
placebo  & $p_2 = 8 / 371 = 0.022$ & $\sqrt{p_2(1-p_2)/371}=0.0075$  \\ \hline
difference &$p_1-p_2=0.056$ & $\sqrt{0.0144^2+0.0075^2}=0.0162$
\end{tabular}\end{center}

We get a 95\% confidence interval for the difference with
   \[ (0.056\pm 1.96\cdot 0.0162) = (0.024, 0.088). \]
(This allows for hypothesis testing.)
}
%% \frame{ % -------------------------------------------------------------------->
%% \frametitle{A digression and a toy example}
%% A study on treatment X for A-individuals found an effect size of 16 with SE
%% 2.1. An independent study on X for B-individuals found an effect size of 9
%% with SE 1.7.
%% <<>>=
%% plot(x = c(9-2*1.7,16+2*2.1), y = c(0,1), type = 'n',
%%      xlab = "", yaxt  = 'n', ylab = "")
%% points(x = c(9,16), y = c(0,1))
%% lines(x = c(9-1.96*1.7, 9+1.96*1.7), y = c(0,0))
%% lines(x = c(16-1.96*2.1, 16+1.96*2.1), y =c(1,1))
%% @
%% Is the effect for A and B individuals statistically significant different?
%% We don't know!
%% }
\frame{ % -------------------------------------------------------------------->
\frametitle{Have we exhausted the Dabigatran example yet?}

It certainly seems so (but it will actually return again later in the lecture!)

\rymda \textbf{Summary of the dabigatran example}:

\begin{center}
\begin{tabular}{|l|lr@{,}l|} \hline
Quantity & Estimate & \multicolumn{2}{c|}{Confidence interval} \\ \hline
$p_1$     & 0.078 & $(0.050$ & \,$0.11)$ \\
%$p_2$     & 0.022 & $(0.007$ & $0.037)$ \\
$p_1-p_2$ & 0.056 & $(0.024$ & \,$0.088)$ \\
OR (p1 vs. p2) & 3.82 & $(1.7$ & \,$9.9)$ \\ \hline
\end{tabular}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Cosmetic skin testing}
To prove a new product is hypoallergenic it should provoke
no more skin reactions than current market leader.

\rymd To test a new product 40 individuals got both products applied
to patches of skin and observed for reaction (yes/no)

\begin{center}\begin{tabular}{ccc} \\ \hline
id & new & market \\ \hline
1 & no & no \\
2 & yes & no \\
3 & no & no \\
$\vdots$ & $\vdots$ & $\vdots$ \\
40 & yes & yes \\ \hline
\end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->

Is the new product as good as the market leader?\\

\rymd The following table is \emph{not} appropriate to answer that question.

\begin{center}\begin{tabular}{|c|cc|}  \hline
     & no & yes \\ \hline
 old & 22 & 18 \\
 new & 32 & 8  \\ \hline
\end{tabular}\end{center}

\emph{The rows are dependent.} %This makes e.g.\ test of risk difference faulty.

\rymd \textbf{Note:} \\

\rymd One \emph{can} estimate (and get confidence intervals) for
$p_1$ and $p_2$ (risk of skin reaction with new and old, respectively).

\rymd \emph{But} it is harder to quantify the SE for risk difference and OR, due to
the dependence.

}
<<mcnemar, include=FALSE>>=
mcbord <- matrix(c(17,5,15,3), byrow=TRUE, ncol=2)
rownames(mcbord) <- c("old:no","old:yes")
colnames(mcbord) <- c("new:no", "new:yes")
mcbord
addmargins(mcbord)
mcnemar.test(mcbord)
mcwrong <- rbind(rowSums(mcbord), colSums(mcbord))
rownames(mcwrong) <- NULL
rownames(mcwrong) <- c("old","new")
colnames(mcwrong) <- c("no", "yes")
mcwrong
addmargins(mcwrong)
prop.test(mcwrong)
@
\frame{ % -------------------------------------------------------------------->
\frametitle{McNemars test for paired data}
\begin{center}
\begin{tabular}{c|c|cc|c}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{new} & \\ \cline{3-4}
\multicolumn{2}{c|}{}  & no & yes & $\sum$ \\ \cline{2-5}
\multirow{2}{*}{market} & no & 17 & 5 & 22 \\ %
& yes & 15 & 3 & 18 \\ \cline{2-5}
\multicolumn{1}{c}{} & $\sum$ & 32 & 8 & 40 \\
\end{tabular}
\end{center}

McNemars test only considers the pairs were
the results are different.

\rymd With new product there are 8 reactions but 3
of them would have happened anyway. The new product 'creates' 5 reactions, whereas the market leader 'creates' 15 reactions. \\

\rymd Switching from the market leader to the new product would benefit 15, make it worse for 5, and have no effect on 20. (In terms of skin reactions.)

\rymd A test statistic can be calculated.
$p$-value for $H_0$:'no difference' is approx 4\%.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Other situations}

Twins being randomized to intervention or placebo:
\begin{center}\begin{tabular}{c|c|cc|}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Placebo}  \\ \cline{3-4}
\multicolumn{2}{c|}{}   & improvement & non  \\ \cline{2-4}
\multirow{2}{*}{Intervention} & improvement & a & b \\
 & non & c & d \\ \cline{2-4}
\end{tabular}\end{center}

\rymda Before/after data:
\begin{center}\begin{tabular}{c|c|cc|}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Before}  \\ \cline{3-4}
\multicolumn{2}{c|}{}   & event & non  \\ \cline{2-4}
\multirow{2}{*}{After} & event & a & b \\
 & non & c & d \\ \cline{2-4}
\end{tabular}\end{center}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[$\chi^2$]{$\chi^2$-tests} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{ % -------------------------------------------------------------------->
\frametitle{Mendel's pea experiment}

One of Mendels pea-experiments was a (dihybrid)
cross between the genes for round/wrinkled seeds and yellow/green seeds.

\begin{center}\begin{tabular}{|c|cccc|c|}  \hline
Type  & RY & RG & WY & WG & Sum\\ \hline
Count ($O$)  & 315 & 108 & 101 & 32 & 558 \\ \hline
\end{tabular}\end{center}

According to his theory, these should appear in ratios of 9:3:3:1.

So, we have a model for $X=$"the type":

\begin{center}\begin{tabular}{|c|cccc|}  \hline
Value $v$ & RY & RG & WY & WG\\ \hline
$\pr(X=v)$ & 9/16 & 3/16 & 3/16 & 1/16 \\ \hline
\end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{$\chi^2$-tests}
$\chi^2$ tests are applied to tabulated data
(i.e. the 'counts'), typically categorical
data. (E.g.\ the Dabigatran data.)

\rymd Like the $t$-test, we can use $\chi^2$ to compare
a  sample against a model
or, compare 2 or more samples against each other.

\rymd $\chi^2$ tests typically calculate a test statistic $Q$ according to the formula
\[ Q = \sum \frac{ (\mbox{observed - expected})^2 }{\mbox{expected}}. \]
$Q$ is compared to a $\chi^2$ distribution with
a parameter (degrees of freedom) that depends on
the situation.
\begin{center}
\fbox{\textbf{This is not an exact test. Rule of thumb: cell count $\geq 5$}.}
\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Comparing data to a model}
$\chi^2$-analysis:

\begin{center}\begin{tabular}{|c|cccc|c|}  \hline
Type  & RY & RG & WY & WG & Sum\\ \hline
Data ($O$)  & 315 & 108 & 101 & 32 & 558 \\ \hline
$H_0$ model ($p$) \ &  9/16 & 3/16 & 3/16 & 1/16 & 1 \\ \hline
Expected ($E=558\times p$)  & 313.9 & 104.6 & 104.6 & 34.9 & 558 \\ \hline
$Q$, i.e. $\,(O-E)^2/E$  & 0.004 & 0.111 & 0.124 & 0.241 & 0.479  \\  \hline
Residuals $\,(O-E)/\sqrt E$ & 0.127 &  0.367 & -0.318 & -0.467 & \\ \hline
\end{tabular}\end{center}


If $H_0$ is correct then $Q$ should be (approximately) $\chi^2(3)$. \\
($3=$ the number of categories $- 1$.)
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Mendels hypothesis seems ok}
The observed test statistic 0.47 is compatible with $H_0$.
<<chisq>>=
dfm <- data.frame(
   pod=factor(rep(c("R", "W"), c(423,133))),
   color=factor(rep(c("Y","G", "Y","G"), c(315,108,101,32)), levels=c("Y", "G"))
)
Tdfm <- with(dfm, table(pod,color))
dfm$type <- factor(paste(dfm$pod, dfm$color, sep=""), levels=c("RY","RG","WY","WG"))
T2dfm <- table(dfm$type)
chi <- chisq.test(T2dfm, p=c(9,3,3,1)/16 )
obs <- chi$statistic
obs.y <- dchisq(obs,3)
par(mar=c(4,4,1,1))
curve(dchisq(x,3), from=0, to=15, xlab="Outcome", ylab="Probability", xlim=c(0,10),
   las=1, cex.lab=1.5, xaxt='n', lwd=2)
q <- qchisq(0.95, 3)
axis(1,at=c(0,obs,5,q, 10), lab=c("0",round(obs,2),"5",round(q,2),"10"))
abline(v=q, lty=2)
arrows(x0=q, y0=0.15,x1=10.2,y1=0.15)
text(x=9, y=0.15, pos=3, label="5%", cex=1.5)
## points(x=obs, y=0, pch=4, cex=2, lwd=2, col=.red)
## text(x=obs+0.5, y=0, "observed", pos=3, cex=1.5)
points(x=obs, y=obs.y, pch=4, cex=2, lwd=2, col=.red)
text(x=obs+0.9, y=obs.y-.02, "observed", pos=3, cex=1.5)
@
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Comparing distributions}
A case control study of coronary heart disease and drinking (none, moderate, heavy). Cases were matched on age, gender and smoking habits.

\begin{center}\begin{tabular}{|c|ccc|c|} \hline
          & non & moderate & heavy & sum \\ \hline
 cases    &  34 &       80 &    18 & 132\\
 controls & 156 &      334 &    38 & 528 \\ \hline
 sum &      190 &      414 &    56 & 660 \\ \hline
\end{tabular}\end{center}

Does drinking habits differ between cases and controls?

If they do not ($H_0$), their distributions should be close to

\begin{center}\begin{tabular}{ccc} \hline
non & moderate & heavy  \\ \hline
28.8\%\,(190/660) & 62.7\%\,(414/660) & 8.48\%\,(56/660) \\ \hline
\end{tabular}\end{center}
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Visualizing the distributions}
<<case_cont, fig.width=10, fig.height=5, include=FALSE>>=
cases <- c(34,80,18)
controls <- c(156, 334, 38)
chd <- cbind(cases, controls)
save(chd, file="data/chd.rdata")
rownames(chd) <- c("non","moderate","heavy")
## barplot(prop.table(chd),
##    beside=TRUE,
##    legend=TRUE,
##    main="Proportions within dataset",
##    col=.seq3,
##    args.legend=c(x="top"))
## points(x=c(1,8), y=c(0,0.5), type='l', lwd=5)
## points(x=c(1,8), y=c(0.5,0), type='l', lwd=5)
barplot(prop.table(chd,2),
   beside=TRUE,
   legend=TRUE,
   main="Proportion within subgroups",
   col=.seq3,
   args.legend=c(x="top"))
@

<<case_cont_code, results='asis'>>=
plot_code <- sprintf("\\includegraphics[scale=0.48]{figure/%s}\n", paste0("case_cont-",1))
cat(plot_code, sep="")
@
}
\frame{ % -------------------------------------------------------------------->
Are drinking categories equidistributed for cases and controls?
\begin{center}\begin{tabular}{|c|ccc|c|} \hline
                   & non  & moderate & heavy & Sum \\ \hline
 observed cases    & 34   &       80 &    18 & 132 \\
 observed controls & 156  &      334 &    38 & 528 \\ \hline \hline
 sum               & 190  &      414 &    56 & 660 \\
 prop. (p=sum/660) & 0.29 &     0.63 &  0.08 & (1) \\ \hline
 expected cases (132$\cdot p$)    & 38.1  & 82.9  & 11.0 & (132) \\
 expected controls (528$\cdot p$) & 152.0 & 331.0 & 44.0 & (527) \\ \hline
 Q cases ((Obs.-Exp.)$^2$/Exp.)   & 0.43  & 0.10  & 4.4  & Tot: \\
 Q controls                       & 0.11  & 0.026 & 1.1  & 6.2 \\ \hline
\end{tabular}\end{center}
The test statistic $Q=6.2$ should be compared to a $\chi^2$ with
(rows-1)$\times$(columns-1)=1*2=2 degrees of freedom.
$p=\pr(Q>6.2)=0.045$.
}
\frame{ % -------------------------------------------------------------------->
So the difference between cases and controls is statistically significant.

\vspace{0.2cm}
The large sample size gives this test a lot of power (ability to find
differences).

\vspace{0.2cm}
Do not forget to look at the estimates!

\begin{center}
\begin{tabular}{|c|ccc|} \hline
                    &  non & moderate & heavy \\ \hline
proportion cases    & 0.26 &     0.61 &  0.13 \\
proportion controls & 0.30 &     0.63 &  0.07 \\ \hline
proportion total    & 0.29 &     0.63 &  0.08 \\ \hline
\end{tabular}
\end{center}

Whether these differences are significant in any other sense
is for the researcher to discuss.
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Which categories deviate?}
One can also look at the 'residuals'.
<<chiq_res>>=
## 1
load("data/chd.rdata")
res <- chisq.test(chd)$resid
rownames(res) <- c("non", "moderate", "heavy")
barplot(res, beside=TRUE, legend=TRUE, main="Residuals",
   col=.seq3,args.legend=c(x="topright"))
@
}
\begin{frame}[fragile] % ----------------------------------------------------->
\frametitle{$\chi^2$ on the dabigatran data}
The $\chi^2$ test can also be applied to our dabigatran data.

\rymda It tests if the distribution of complications (bleeding/not)
is the same for the two groups.

\rymda Output from my software:
<<back2chi, include=FALSE>>=
bord <- matrix(c(27,320,8,363), byrow=TRUE, ncol=2)
rownames(bord) <- c("dabigatran","placebo")
colnames(bord) <- c("yes", "no")
chisq.test(bord)
rm(bord)
@
\begin{verbatim}
#  Pearson's Chi-squared test with Yates'
#  continuity correction
#
#  data:  bord
#  X-squared = 11.05, df = 1, p-value = 0.0008869
\end{verbatim}

(Recall that Fisher's exact test gave $p=0.0004458$.)
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[More]{Additional analysis} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \frame{ % -------------------------------------------------------------------->
% \frametitle{$\chi^2$-test for trend}
% In the example with Dabigatran more data was available:
% \begin{multicols}{2}
% $\phantom{.}$
% \vspace{0.5cm}
% \begin{tabular}{|c|cc|} \hline
% & \multicolumn{2}{c|}{Bleeding} \\ \hline
% Dose     &  Yes & No \\ \hline
% 150 mg&  27 &320\\
% 100 mg&  32 &374\\
% 75 mg &  16 &352\\
% 50 mg &  13 &356\\ \hline
% \end{tabular}
% \includegraphics[scale=0.3]{R/trend.pdf}
% \end{multicols}
% The $\chi^2$ test for trend yields a statistically significant result.\\
% (Details omitted.)
% }
\frame{ % -------------------------------------------------------------------->
\frametitle{Adjusting for a confounder}
Comparison of open surgery (OS) and percutaneous nephrolithotomy (PN)
for removal of kidney stones. \\
(Data illustrates Simpson's paradox.)
<<mantel_haenzel, include=FALSE>>=
mhbord <- array(
   data=c(81,6,234,36,192,71,55,25),
   dim=c(2,2,2),
   dimnames=list(
      c("Success", "Failure"),
      c("OS", "PN"),
      c("Small stones", "Large stones")
   ))
mantelhaen.test(mhbord)
rm(mhbord)
@
\begin{center}\begin{tabular}{|c|cc||cc|cc|}
\multicolumn{3}{c}{} & \multicolumn{4}{c}{Adjusted for size} \\ \cline{4-7}
\multicolumn{1}{c}{}&\multicolumn{2}{c||}{Total} & \multicolumn{2}{c|}{Small stones} & \multicolumn{2}{c|}{Large stones} \\ \cline{2-7}
\multicolumn{1}{c|}{} &  OS  &  PN &   OS &  PN &  OS &  PN \\ \hline
Success               & 273  & 289 &   81 & 234 & 192 &  55 \\  \hline
Failure               &  77  &  61 &    6 &  36 &  71 &  25 \\ \hline \hline
Odds (for success)    & 3.5 & 4.7 & 13.5 & 6.5 & 2.7 & 2.2 \\ \hline
Odds ratio (OS / PN) &\multicolumn{2}{c||}{0.75} &\multicolumn{2}{c|}{2.1} &
\multicolumn{2}{c|}{1.2} \\ \hline \hline
(Percent success      &  78\% & 83\% & 93\% & 87\% & 73\% & 69\%) \\ \hline
\end{tabular}\end{center}

Here it seems like we should adjust for stone size. \\
(\textbf{The Mantel-Haenszel} test is a way to analyse several contingency tables.)
}
\frame{ % -------------------------------------------------------------------->
\frametitle{Adjusting for multiple confounders}
In observational studies we typically gather more information. E.g.\
\begin{center}\begin{tabular}{|ccccccc|} \hline
Ind.\ & Bleeding & DE Dose & Age & Gender & Weight & \ldots \\ \hline
1     &      Yes &      50 &  75 &      M &     83 & \ldots \\
2     &       No &      75 &  64 &      F &     77 & \ldots  \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ &  \\ \hline
\end{tabular}\end{center}

When medicine is \textbf{not} randomized a simple cross tabulation analysis of 'Bleeding'
versus 'DE Dose' is at risk of confounding.

\vspace{0.2cm}
One way to deal with this is logistic regression (more on that in a later lecture).
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\section{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\subsection{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{ % -------------------------------------------------------------------->
\frametitle{References}

\begin{itemize}
\item Chapters 23-25: Petrie \& Sabin. \emph{Medical Statistics at a Glance}, Wiley-Blackwell (2009).
\item Grant, R.\ L.: Converting an odds ratio to a range of plausible relative risks for better communication of research findings, \emph{BMJ} \textbf{348} (2014) 7 pages.
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
  \frametitle{First poll}
  \newcommand{\lada}{\fbox{$\phantom{x}$}}
\textbf{Question 1:} You are at 3\% risk of a disease. Would you rather
\begin{itemize}
\item[\lada] Have a 1\%-point risk reduction?
\item[\lada] Halve your odds?
\item[\lada] Doesn't matter
\end{itemize}
\textbf{Question 2:} You are facing a 50\% risk of a disease. Would you rather
\begin{itemize}
\item[\lada] Halve your risk
\item[\lada] Halve your odds
\item[\lada] Doesn't matter
\end{itemize}
}
\frame{ % -------------------------------------------------------------------->
  \frametitle{Second poll}
  \newcommand{\lada}{\fbox{$\phantom{x}$}}
\textbf{Question 1:} The OR for success between procedure A and B is 2. Check
those that are necessarily true:
\begin{itemize}
\item[\lada] the A procedure has >50\% chance of success
\item[\lada] A has a higher success rate than B
\item[\lada] A has double the success rate of B
\end{itemize}
\textbf{Question 2:} Drug X has a side effect Y, experienced by 5\% of the
users, a risk researches are trying to halve. A study on a modification of X
found that the OR for Y is 0.2 (.07, .44) concerning side effects. Did the
researchers succeed?
\begin{itemize}
\item[\lada] Yes
\item[\lada] No
\item[\lada] Inconclusive.
\end{itemize}
}

\end{document} # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


%% \frame{ % -------------------------------------------------------------------->
%%   \frametitle{poll}
%%   \newcommand{\lada}{\fbox{$\phantom{x}$}}
%% \textbf{Question ?:}
%% \begin{itemize}
%% \item[\lada] text
%% \item[\lada] text
%% \item[\lada] text
%% \end{itemize}
%% }
